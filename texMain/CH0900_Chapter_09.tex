% !TeX root = ThesisMain.tex
% !TeX program = XeLaTeX
% !TeX encoding = UTF-8
% !TeX spellcheck = en_GB

\documentclass[../ThesisMain]{subfiles}
\ifSubfilesClassLoaded{}{}%

\begin{document}
\doublespacing%
\chapter{OpenFOAM Integration and Comprehensive Evaluation}\label{chap:openfoam}

This chapter presents the integration of machine learning wall functions into OpenFOAM and provides comprehensive evaluation across multiple dimensions: accuracy, computational efficiency, generalization, and robustness \cite{2409_19851_v1, 2404_03542_v1}. While Chapters~\ref{chap:baseline}--\ref{chap:pinn} focused on model development and offline prediction of wall quantities ($\tau_w$, $q_w$), this chapter evaluates how the integrated wall functions affect \textbf{complete flow field predictions} in production CFD simulations. The evaluation uses canonical benchmark geometries---including three-dimensional cases---and systematic comparison against established wall function approaches \cite{2206_05226_v2, driver1985, breuer2009}.

%=============================================================================
\section{OpenFOAM Integration Architecture}
\label{sec:ch9_integration}
%=============================================================================

\subsection{Motivation for Production Integration}

Neural network wall functions trained in previous chapters achieve high accuracy in offline testing. However, deployment in production CFD introduces fundamental challenges:

\begin{enumerate}
    \item \textbf{Circular dependency}: Wall shear stress $\tau_w$ depends on friction velocity $u_\tau = \sqrt{\tau_w / \rho}$, which appears in input features. This coupling must be resolved iteratively.

    \item \textbf{Field coupling}: The wall function affects not just wall quantities but the entire flow field through boundary condition enforcement. Errors can propagate and amplify.

    \item \textbf{Distribution shift}: Training data comes from fine-mesh simulations. At deployment, the ML wall function modifies the flow field, creating input distributions different from training.

    \item \textbf{Computational efficiency}: Wall functions are evaluated at every wall face, every iteration. Inference must not dominate simulation cost.

    \item \textbf{Numerical stability}: The wall function must provide bounded, physically consistent outputs even for unexpected inputs during iterative convergence.
\end{enumerate}

\subsection{Implementation Architecture}

Figure~\ref{fig:ch9_architecture} illustrates the integration architecture within OpenFOAM's boundary condition framework.

\begin{figure}[H]
    \centering
    \fbox{\parbox{0.9\textwidth}{\centering\vspace{3cm}
    \textbf{[PLACEHOLDER FIGURE]}\\
    Integration architecture showing: OpenFOAM solver loop $\rightarrow$ boundary condition call $\rightarrow$ feature extraction $\rightarrow$ ML inference $\rightarrow$ $\nu_t$ update $\rightarrow$ field solve
    \vspace{3cm}}}
    \caption{OpenFOAM integration architecture. The ML wall function boundary condition is called during each SIMPLE/PISO iteration, extracts physics features from the local flow field, performs neural network inference, and returns turbulent viscosity $\nu_t$ at wall faces.}
    \label{fig:ch9_architecture}
\end{figure}

The implementation creates a custom wall function class inheriting from OpenFOAM's standard infrastructure:

\begin{verbatim}
class mlNutWallFunctionFvPatchScalarField
    : public nutWallFunctionFvPatchScalarField
{
    // ML model and configuration
    autoPtr<mlModelLoader> model_;
    word modelType_;
    bool usePhysicsFeatures_;

    // Standard OpenFOAM interface
    virtual void updateCoeffs();
    virtual tmp<scalarField> calcNut() const;
};
\end{verbatim}

\subsection{Model Loading and Inference Backends}

Three backends provide flexibility between performance and deployment ease:

\begin{table}[H]
\centering
\caption{Model loading backends for OpenFOAM integration.}
\label{tab:ch9_backends}
\begin{tabular}{lccc}
\toprule
\textbf{Backend} & \textbf{Dependencies} & \textbf{Inference Speed} & \textbf{Recommended For} \\
\midrule
Native C++ & None & Fastest & Production deployment \\
ONNX Runtime & onnxruntime & Fast & Cross-platform portability \\
LibTorch & PyTorch C++ & Fast & Full PyTorch operator support \\
\bottomrule
\end{tabular}
\end{table}

The \textbf{native C++ backend} is recommended for production as it requires no external dependencies and achieves inference times under $0.5~\mu s$ per wall face.

%=============================================================================
\section{Evaluation Methodology}
\label{sec:ch9_methodology}
%=============================================================================

\subsection{Evaluation Dimensions}

The comprehensive evaluation assesses performance across six dimensions:

\begin{enumerate}
    \item \textbf{Accuracy}: How well does the wall function predict wall quantities and flow fields?
    \item \textbf{Computational efficiency}: What is the overhead compared to standard wall functions?
    \item \textbf{Generalization}: How does performance degrade on unseen geometries and conditions?
    \item \textbf{Robustness}: Does the wall function remain stable across mesh densities and solver settings?
    \item \textbf{Physical consistency}: Are predictions physically plausible (correct signs, bounds, trends)?
    \item \textbf{Separation prediction}: Can the wall function correctly identify and predict separated flow regions?
\end{enumerate}

\subsection{Comparison Methods}

The ML wall function is compared against established approaches:

\begin{table}[H]
\centering
\caption{Wall function methods included in comparative evaluation.}
\label{tab:ch9_comparison_methods}
\begin{tabular}{lll}
\toprule
\textbf{Method} & \textbf{Description} & \textbf{Reference} \\
\midrule
\multicolumn{3}{l}{\textit{Standard Wall Functions}} \\
\quad nutUSpaldingWallFunction & Spalding law (continuous) & OpenFOAM default \\
\quad nutUWallFunction & Log-law with viscous blending & OpenFOAM \\
\quad nutkWallFunction & $k$-based wall function & OpenFOAM \\
\midrule
\multicolumn{3}{l}{\textit{Enhanced Wall Functions}} \\
\quad nutUBlendedWallFunction & Enhanced blending & OpenFOAM \\
\quad omegaWallFunction & $\omega$-based (Menter) & \cite{menter1994} \\
\midrule
\multicolumn{3}{l}{\textit{Low-Reynolds-Number Treatment}} \\
\quad Wall-resolved (no WF) & Direct integration to wall & Reference solution \\
\midrule
\multicolumn{3}{l}{\textit{Machine Learning (This Work)}} \\
\quad ML-Baseline & Primitive features (6 inputs) & Ch.~\ref{chap:baseline} \\
\quad ML-PhysicsInputs & Physics features (58 inputs) & Ch.~\ref{chap:physics_features} \\
\quad ML-PhysicsLayers & Interpretable architecture & Ch.~\ref{chap:neurons} \\
\quad ML-PINN & Physics-informed loss & Ch.~\ref{chap:pinn} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Benchmark Test Cases}

Table~\ref{tab:ch9_test_cases} summarizes the test cases used for comprehensive evaluation, organized by complexity and distribution shift from training data.

\begin{table}[H]
\centering
\caption{Benchmark test cases for comprehensive evaluation.}
\label{tab:ch9_test_cases}
\begin{tabular}{llccc}
\toprule
\textbf{Case} & \textbf{Challenge} & \textbf{Dim.} & \textbf{Separation} & \textbf{Distribution} \\
\midrule
\multicolumn{5}{l}{\textit{In-Distribution (Training-like)}} \\
\quad Channel flow & Equilibrium attached & 2D & No & In \\
\quad Diffuser (flat wall) & Mild APG & 2D & No & In \\
\midrule
\multicolumn{5}{l}{\textit{Mild Out-of-Distribution}} \\
\quad Channel ($Re = 30{,}000$) & Reynolds extrapolation & 2D & No & Mild OOD \\
\quad Diffuser (curved wall) & Wall curvature & 2D & Incipient & Mild OOD \\
\midrule
\multicolumn{5}{l}{\textit{Strong Out-of-Distribution}} \\
\quad Backward-facing step & Geometry-induced separation & 2D & Strong & Strong OOD \\
\quad Periodic hills & Cyclic separation & 2D & Strong & Strong OOD \\
\quad Buice-Eaton diffuser & APG-induced separation & 2D & Strong & Strong OOD \\
\quad Wall-mounted hump & Smooth separation & 2D & Strong & Strong OOD \\
\midrule
\multicolumn{5}{l}{\textit{Three-Dimensional Cases}} \\
\quad 3D backward step & Spanwise effects & 3D & Strong & Strong OOD \\
\quad 3D periodic hills & 3D separation bubble & 3D & Strong & Strong OOD \\
\quad Square duct & Secondary flows & 3D & No & Strong OOD \\
\quad Ahmed body & Automotive wake & 3D & Strong & Strong OOD \\
\bottomrule
\end{tabular}
\end{table}

%=============================================================================
\section{Accuracy Evaluation}
\label{sec:ch9_accuracy}
%=============================================================================

This section presents accuracy results comparing ML wall functions against standard approaches across all benchmark cases.

\subsection{Wall Quantity Prediction Accuracy}

\subsubsection{Skin Friction Coefficient}

Figure~\ref{fig:ch9_cf_comparison_attached} compares skin friction predictions for attached flow cases.

\begin{figure}[H]
    \centering
    \fbox{\parbox{0.95\textwidth}{\centering\vspace{4cm}
    \textbf{[PLACEHOLDER FIGURE]}\\
    (a) Channel flow $C_f$ vs $Re$ for all methods\\
    (b) Diffuser flat wall $C_f$ vs $x/H$\\
    (c) Error bar chart comparing methods
    \vspace{4cm}}}
    \caption{Skin friction coefficient comparison for attached flow cases. (a) Channel flow across Reynolds numbers. (b) Diffuser flat wall region. (c) Summary of relative errors for all methods compared to wall-resolved reference.}
    \label{fig:ch9_cf_comparison_attached}
\end{figure}

Figure~\ref{fig:ch9_cf_comparison_separated} presents the critical comparison for separated flow cases where standard wall functions are known to fail.

\begin{figure}[H]
    \centering
    \fbox{\parbox{0.95\textwidth}{\centering\vspace{5cm}
    \textbf{[PLACEHOLDER FIGURE]}\\
    (a) Backward-facing step $C_f$ vs $x/H$: Experiment vs all methods\\
    (b) Periodic hills $C_f$ over one period\\
    (c) Buice-Eaton diffuser $C_f$ along inclined wall\\
    (d) Wall-mounted hump $C_f$ distribution\\
    Showing: Experiment/DNS (symbols), wall-resolved (black line), standard WF (dashed), ML methods (colored lines)
    \vspace{5cm}}}
    \caption{Skin friction coefficient comparison for separated flow benchmark cases. Standard wall functions (dashed lines) fail to predict negative $C_f$ in recirculation zones. ML wall functions (solid colored lines) show varying degrees of improvement.}
    \label{fig:ch9_cf_comparison_separated}
\end{figure}

\subsubsection{Separation and Reattachment Point Prediction}

Table~\ref{tab:ch9_separation_points} quantifies separation prediction accuracy.

\begin{table}[H]
\centering
\caption{Separation and reattachment point predictions for benchmark cases.}
\label{tab:ch9_separation_points}
\begin{tabular}{lccccc}
\toprule
\textbf{Case} & \textbf{Experiment} & \textbf{Std. WF} & \textbf{ML-Baseline} & \textbf{ML-Physics} & \textbf{ML-PINN} \\
\midrule
\multicolumn{6}{l}{\textit{Separation point $x_{sep}/H$}} \\
\quad Backward step & 0.0 & 0.0 & --- & --- & --- \\
\quad Periodic hills & 0.22 & --- & --- & --- & --- \\
\quad Buice-Eaton & 7.4 & --- & --- & --- & --- \\
\quad Hump & 0.66 & --- & --- & --- & --- \\
\midrule
\multicolumn{6}{l}{\textit{Reattachment point $x_{reatt}/H$}} \\
\quad Backward step & 6.26 & --- & --- & --- & --- \\
\quad Periodic hills & 4.72 & --- & --- & --- & --- \\
\quad Buice-Eaton & 29.2 & --- & --- & --- & --- \\
\quad Hump & 1.11 & --- & --- & --- & --- \\
\bottomrule
\multicolumn{6}{l}{\small Values to be filled from simulation results.}
\end{tabular}
\end{table}

\subsubsection{Wall Heat Flux}

Figure~\ref{fig:ch9_thermal_comparison} presents thermal wall function performance where benchmark data is available.

\begin{figure}[H]
    \centering
    \fbox{\parbox{0.95\textwidth}{\centering\vspace{4cm}
    \textbf{[PLACEHOLDER FIGURE]}\\
    (a) Channel flow Stanton number vs $Re$\\
    (b) Flat plate thermal boundary layer $St$ vs $Re_x$\\
    (c) Heated backward step $St/St_0$ ratio (Vogel \& Eaton data)\\
    (d) Summary error comparison
    \vspace{4cm}}}
    \caption{Thermal wall function comparison. (a,b) Attached flow cases where all methods perform reasonably. (c) Separated flow case showing enhanced heat transfer in reattachment region. (d) Summary of Stanton number prediction errors.}
    \label{fig:ch9_thermal_comparison}
\end{figure}

\subsection{Full Flow Field Accuracy}

Beyond wall quantities, the integrated wall function affects the entire flow field. This section evaluates velocity and pressure field predictions.

\subsubsection{Velocity Profiles}

Figure~\ref{fig:ch9_velocity_profiles} compares velocity profiles at key stations.

\begin{figure}[H]
    \centering
    \fbox{\parbox{0.95\textwidth}{\centering\vspace{5cm}
    \textbf{[PLACEHOLDER FIGURE]}\\
    Velocity profiles $U/U_{ref}$ vs $y/H$ at multiple stations:\\
    (a) Backward-facing step: $x/H = 1, 4, 6, 8$ (recirculation $\rightarrow$ recovery)\\
    (b) Periodic hills: $x/H = 0.5, 2, 4, 6, 8$ (separation $\rightarrow$ attached)\\
    (c) Buice-Eaton diffuser: $x/H = 5, 15, 25, 35$\\
    Comparing: Experiment (symbols), wall-resolved (black), standard WF (dashed), ML (colored)
    \vspace{5cm}}}
    \caption{Velocity profile comparison at selected streamwise stations. The ML wall function's influence propagates throughout the boundary layer, not just the wall-adjacent cell.}
    \label{fig:ch9_velocity_profiles}
\end{figure}

\subsubsection{Pressure Distribution}

Figure~\ref{fig:ch9_pressure_distribution} presents surface pressure predictions.

\begin{figure}[H]
    \centering
    \fbox{\parbox{0.95\textwidth}{\centering\vspace{4cm}
    \textbf{[PLACEHOLDER FIGURE]}\\
    Pressure coefficient $C_p$ vs $x/H$:\\
    (a) Backward-facing step\\
    (b) Periodic hills\\
    (c) Wall-mounted hump\\
    (d) Summary of pressure recovery prediction accuracy
    \vspace{4cm}}}
    \caption{Surface pressure coefficient distribution. Accurate pressure prediction is critical for engineering applications (drag, lift). The wall function affects pressure through its influence on separation location and recirculation zone size.}
    \label{fig:ch9_pressure_distribution}
\end{figure}

\subsubsection{Turbulent Quantities}

Figure~\ref{fig:ch9_turbulent_quantities} shows predictions of turbulent kinetic energy and Reynolds stresses.

\begin{figure}[H]
    \centering
    \fbox{\parbox{0.95\textwidth}{\centering\vspace{4cm}
    \textbf{[PLACEHOLDER FIGURE]}\\
    (a) Turbulent kinetic energy $k$ profiles at selected stations\\
    (b) Peak $k$ location vs streamwise position\\
    (c) Near-wall $k$ distribution comparison\\
    (d) Turbulent viscosity $\nu_t$ profiles
    \vspace{4cm}}}
    \caption{Turbulent quantity predictions. The wall function boundary condition directly specifies $\nu_t$ at walls, which influences $k$ and $\omega$ through the transport equations.}
    \label{fig:ch9_turbulent_quantities}
\end{figure}

\subsection{Accuracy Summary}

Table~\ref{tab:ch9_accuracy_summary} provides a quantitative summary of accuracy metrics across all cases and methods.

\begin{table}[H]
\centering
\caption{Accuracy summary: Mean absolute percentage error (MAPE) for wall quantities.}
\label{tab:ch9_accuracy_summary}
\begin{tabular}{lcccccc}
\toprule
& \multicolumn{3}{c}{\textbf{$C_f$ Error (\%)}} & \multicolumn{3}{c}{\textbf{$St$ Error (\%)}} \\
\cmidrule(lr){2-4} \cmidrule(lr){5-7}
\textbf{Method} & Attached & Separated & Overall & Attached & Separated & Overall \\
\midrule
Standard (Spalding) & --- & --- & --- & --- & --- & --- \\
Standard (log-law) & --- & --- & --- & --- & --- & --- \\
ML-Baseline & --- & --- & --- & --- & --- & --- \\
ML-PhysicsInputs & --- & --- & --- & --- & --- & --- \\
ML-PhysicsLayers & --- & --- & --- & --- & --- & --- \\
ML-PINN & --- & --- & --- & --- & --- & --- \\
\bottomrule
\multicolumn{7}{l}{\small Values to be filled from simulation results.}
\end{tabular}
\end{table}

%=============================================================================
\section{Computational Efficiency}
\label{sec:ch9_efficiency}
%=============================================================================

Computational overhead is critical for practical adoption. This section quantifies the cost of ML wall functions relative to standard approaches.

\subsection{Inference Time per Wall Face}

Figure~\ref{fig:ch9_inference_time} presents inference timing measurements.

\begin{figure}[H]
    \centering
    \fbox{\parbox{0.95\textwidth}{\centering\vspace{4cm}
    \textbf{[PLACEHOLDER FIGURE]}\\
    (a) Inference time per wall face ($\mu$s) for each backend and model\\
    (b) Breakdown: feature extraction vs neural network vs post-processing\\
    (c) Comparison with standard wall function evaluation time\\
    (d) Scaling with network size (number of parameters)
    \vspace{4cm}}}
    \caption{Inference timing analysis. The native C++ backend achieves sub-microsecond inference, comparable to standard wall function evaluation.}
    \label{fig:ch9_inference_time}
\end{figure}

\subsection{Overall Simulation Cost}

Figure~\ref{fig:ch9_simulation_cost} compares total simulation time for complete cases.

\begin{figure}[H]
    \centering
    \fbox{\parbox{0.95\textwidth}{\centering\vspace{4cm}
    \textbf{[PLACEHOLDER FIGURE]}\\
    (a) Total wall-clock time for backward-facing step (varying mesh sizes)\\
    (b) Percentage overhead of ML wall function vs standard\\
    (c) Breakdown: solver time vs wall function time vs I/O\\
    (d) Scaling study: overhead vs number of wall faces
    \vspace{4cm}}}
    \caption{Total simulation cost comparison. The ML wall function adds minimal overhead ($<5\%$) for typical industrial meshes.}
    \label{fig:ch9_simulation_cost}
\end{figure}

\subsection{Memory Requirements}

Table~\ref{tab:ch9_memory} summarizes memory requirements for each model variant.

\begin{table}[H]
\centering
\caption{Memory requirements for ML wall function models.}
\label{tab:ch9_memory}
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{Parameters} & \textbf{Model Size (KB)} & \textbf{Runtime Memory (MB)} \\
\midrule
ML-Baseline (6 inputs) & --- & --- & --- \\
ML-PhysicsInputs (58 inputs) & --- & --- & --- \\
ML-PhysicsLayers & --- & --- & --- \\
ML-PINN & --- & --- & --- \\
\midrule
Standard wall function & N/A & N/A & --- \\
\bottomrule
\multicolumn{4}{l}{\small Values to be filled from implementation measurements.}
\end{tabular}
\end{table}

\subsection{Efficiency Summary}

\begin{table}[H]
\centering
\caption{Computational efficiency summary.}
\label{tab:ch9_efficiency_summary}
\begin{tabular}{lccc}
\toprule
\textbf{Metric} & \textbf{Standard WF} & \textbf{ML (Native)} & \textbf{ML (LibTorch)} \\
\midrule
Inference time per face ($\mu$s) & --- & --- & --- \\
Total overhead (\%) & 0\% & --- & --- \\
Convergence iterations & --- & --- & --- \\
Memory overhead (MB) & 0 & --- & --- \\
\bottomrule
\end{tabular}
\end{table}

%=============================================================================
\section{Generalization Evaluation}
\label{sec:ch9_generalization}
%=============================================================================

Generalization---performance on unseen conditions---is the key challenge for ML methods. This section systematically evaluates generalization across multiple axes.

\subsection{Reynolds Number Extrapolation}

Figure~\ref{fig:ch9_re_generalization} shows performance when extrapolating beyond the training Reynolds number range.

\begin{figure}[H]
    \centering
    \fbox{\parbox{0.95\textwidth}{\centering\vspace{4cm}
    \textbf{[PLACEHOLDER FIGURE]}\\
    (a) $C_f$ error vs Reynolds number (training range shaded)\\
    (b) Channel flow results at $Re = 5{,}000$, $10{,}000$, $20{,}000$, $50{,}000$, $100{,}000$\\
    (c) Extrapolation degradation curve for each method\\
    (d) Comparison: ML degradation vs standard WF error
    \vspace{4cm}}}
    \caption{Reynolds number generalization. Training data covers $Re = 8{,}000$--$24{,}000$. Performance is evaluated at both interpolation and extrapolation conditions.}
    \label{fig:ch9_re_generalization}
\end{figure}

\subsection{Geometry Generalization}

Figure~\ref{fig:ch9_geometry_generalization} evaluates performance on novel geometries not seen during training.

\begin{figure}[H]
    \centering
    \fbox{\parbox{0.95\textwidth}{\centering\vspace{5cm}
    \textbf{[PLACEHOLDER FIGURE]}\\
    Error vs geometry ``distance'' from training:\\
    (a) In-distribution: diffuser within training parameters\\
    (b) Mild OOD: diffuser with different angles/expansion ratios\\
    (c) Strong OOD: backward step, periodic hills, hump\\
    (d) Novel geometry: Ahmed body, airfoil\\
    Bar chart showing $C_f$ MAPE for each category
    \vspace{5cm}}}
    \caption{Geometry generalization. Performance degrades predictably as geometry deviates from training distribution, but ML methods maintain advantage over standard wall functions.}
    \label{fig:ch9_geometry_generalization}
\end{figure}

\subsection{Three-Dimensional Generalization}

A critical question is whether models trained on 2D data generalize to 3D flows. Figure~\ref{fig:ch9_3d_generalization} presents 3D test case results.

\begin{figure}[H]
    \centering
    \fbox{\parbox{0.95\textwidth}{\centering\vspace{6cm}
    \textbf{[PLACEHOLDER FIGURE]}\\
    3D test case results:\\
    (a) 3D backward-facing step: centerline $C_f$ and spanwise variation\\
    (b) 3D periodic hills: separation line topology\\
    (c) Square duct: secondary flow effects on wall quantities\\
    (d) Ahmed body: rear slant $C_f$ distribution\\
    Comparing 2D-trained ML vs standard WF vs reference (LES/experiment)
    \vspace{6cm}}}
    \caption{Three-dimensional generalization. Models trained on 2D simulations are evaluated on 3D flows with spanwise variations, secondary flows, and 3D separation.}
    \label{fig:ch9_3d_generalization}
\end{figure}

\subsubsection{3D Backward-Facing Step}

\begin{figure}[H]
    \centering
    \fbox{\parbox{0.95\textwidth}{\centering\vspace{4cm}
    \textbf{[PLACEHOLDER FIGURE]}\\
    (a) 3D geometry and mesh (isometric view)\\
    (b) Wall $C_f$ contours on bottom wall\\
    (c) Centerline $C_f$ vs $x/H$: experiment, LES reference, standard WF, ML WF\\
    (d) Spanwise $C_f$ variation at $x/H = 3$ (recirculation) and $x/H = 8$ (recovery)
    \vspace{4cm}}}
    \caption{3D backward-facing step results. Spanwise variations in the recirculation zone test the wall function's ability to handle 3D effects.}
    \label{fig:ch9_3d_backstep}
\end{figure}

\subsubsection{3D Periodic Hills}

\begin{figure}[H]
    \centering
    \fbox{\parbox{0.95\textwidth}{\centering\vspace{4cm}
    \textbf{[PLACEHOLDER FIGURE]}\\
    (a) 3D periodic hills geometry (showing spanwise extent)\\
    (b) Separation and reattachment lines on bottom wall\\
    (c) Streamwise $C_f$ at $z/H = 0$ (centerline) and $z/H = 2$ (off-center)\\
    (d) Spanwise-averaged $C_f$ comparison
    \vspace{4cm}}}
    \caption{3D periodic hills results. The 3D separation bubble structure differs from 2D, testing model robustness to three-dimensional effects.}
    \label{fig:ch9_3d_periodic_hills}
\end{figure}

\subsubsection{Ahmed Body (Automotive Benchmark)}

\begin{figure}[H]
    \centering
    \fbox{\parbox{0.95\textwidth}{\centering\vspace{5cm}
    \textbf{[PLACEHOLDER FIGURE]}\\
    (a) Ahmed body geometry (25° and 35° rear slant angles)\\
    (b) Surface $C_f$ contours\\
    (c) Rear slant $C_f$ profile\\
    (d) Base pressure coefficient\\
    (e) Drag coefficient comparison: experiment, LES, RANS+standard WF, RANS+ML WF
    \vspace{5cm}}}
    \caption{Ahmed body automotive benchmark. This practical test case evaluates wall function performance on a real-world geometry with complex 3D separation.}
    \label{fig:ch9_ahmed_body}
\end{figure}

\subsection{Generalization Summary}

Table~\ref{tab:ch9_generalization_summary} quantifies generalization performance.

\begin{table}[H]
\centering
\caption{Generalization summary: $C_f$ MAPE (\%) by distribution shift category.}
\label{tab:ch9_generalization_summary}
\begin{tabular}{lcccc}
\toprule
\textbf{Method} & \textbf{In-Dist.} & \textbf{Mild OOD} & \textbf{Strong OOD} & \textbf{3D Cases} \\
\midrule
Standard (Spalding) & --- & --- & --- & --- \\
ML-Baseline & --- & --- & --- & --- \\
ML-PhysicsInputs & --- & --- & --- & --- \\
ML-PINN & --- & --- & --- & --- \\
\bottomrule
\end{tabular}
\end{table}

%=============================================================================
\section{Robustness Evaluation}
\label{sec:ch9_robustness}
%=============================================================================

Robustness---consistent performance across varying conditions---is essential for production deployment.

\subsection{Mesh Sensitivity}

Figure~\ref{fig:ch9_mesh_sensitivity} evaluates sensitivity to mesh resolution and $y^+$ values.

\begin{figure}[H]
    \centering
    \fbox{\parbox{0.95\textwidth}{\centering\vspace{5cm}
    \textbf{[PLACEHOLDER FIGURE]}\\
    (a) $C_f$ vs mesh density (coarse $\rightarrow$ fine) for backward-facing step\\
    (b) $C_f$ error vs first cell $y^+$ (range: $1$ to $100$)\\
    (c) Comparison: ML robustness vs standard WF $y^+$ sensitivity\\
    (d) Recommended $y^+$ operating range for ML wall function
    \vspace{5cm}}}
    \caption{Mesh sensitivity analysis. A robust wall function should maintain accuracy across a range of $y^+$ values, enabling use on practical meshes without strict $y^+$ requirements.}
    \label{fig:ch9_mesh_sensitivity}
\end{figure}

\subsection{Numerical Stability}

Figure~\ref{fig:ch9_stability} presents convergence behavior and stability analysis.

\begin{figure}[H]
    \centering
    \fbox{\parbox{0.95\textwidth}{\centering\vspace{4cm}
    \textbf{[PLACEHOLDER FIGURE]}\\
    (a) Residual convergence history: standard WF vs ML WF\\
    (b) Number of iterations to convergence across all test cases\\
    (c) Cases with convergence issues (if any)\\
    (d) Wall function blending effect on stability
    \vspace{4cm}}}
    \caption{Numerical stability analysis. The ML wall function should not degrade solver convergence compared to standard wall functions.}
    \label{fig:ch9_stability}
\end{figure}

\subsection{Input Perturbation Sensitivity}

Figure~\ref{fig:ch9_perturbation} tests sensitivity to input perturbations and noise.

\begin{figure}[H]
    \centering
    \fbox{\parbox{0.95\textwidth}{\centering\vspace{4cm}
    \textbf{[PLACEHOLDER FIGURE]}\\
    (a) Output change vs input perturbation magnitude\\
    (b) Gradient magnitude (sensitivity) for each input feature\\
    (c) Comparison of model variants: which is most/least sensitive?\\
    (d) Adversarial input detection (out-of-distribution flags)
    \vspace{4cm}}}
    \caption{Input perturbation sensitivity. Robust models should have bounded output changes for small input perturbations.}
    \label{fig:ch9_perturbation}
\end{figure}

\subsection{Robustness Summary}

Table~\ref{tab:ch9_robustness_summary} summarizes robustness metrics.

\begin{table}[H]
\centering
\caption{Robustness summary across evaluation dimensions.}
\label{tab:ch9_robustness_summary}
\begin{tabular}{lcccc}
\toprule
\textbf{Metric} & \textbf{Std. WF} & \textbf{ML-Baseline} & \textbf{ML-Physics} & \textbf{ML-PINN} \\
\midrule
$y^+$ operating range & 30--300 & --- & --- & --- \\
Mesh independence index & --- & --- & --- & --- \\
Convergence success rate (\%) & --- & --- & --- & --- \\
Max output sensitivity & N/A & --- & --- & --- \\
\bottomrule
\end{tabular}
\end{table}

%=============================================================================
\section{Physical Consistency}
\label{sec:ch9_physical_consistency}
%=============================================================================

Physical consistency ensures predictions respect fundamental physics, even when generalizing beyond training data.

\subsection{Sign Consistency in Separated Flows}

Figure~\ref{fig:ch9_sign_consistency} evaluates whether the wall function correctly predicts negative $\tau_w$ in recirculation zones.

\begin{figure}[H]
    \centering
    \fbox{\parbox{0.95\textwidth}{\centering\vspace{4cm}
    \textbf{[PLACEHOLDER FIGURE]}\\
    (a) Predicted vs true $\tau_w$ sign across all test cases\\
    (b) Confusion matrix for sign prediction (positive/negative/zero)\\
    (c) Spatial distribution of sign errors for backward-facing step\\
    (d) Sign prediction accuracy by method
    \vspace{4cm}}}
    \caption{Sign consistency in separated flows. Standard wall functions cannot predict negative $\tau_w$. ML methods should correctly identify recirculation zones.}
    \label{fig:ch9_sign_consistency}
\end{figure}

\subsection{Boundedness and Physical Limits}

Figure~\ref{fig:ch9_boundedness} checks whether predictions respect physical bounds.

\begin{figure}[H]
    \centering
    \fbox{\parbox{0.95\textwidth}{\centering\vspace{4cm}
    \textbf{[PLACEHOLDER FIGURE]}\\
    (a) Distribution of predicted $\nu_t$ values (should be $\geq 0$)\\
    (b) Distribution of predicted $C_f$ values vs physical range\\
    (c) Percentage of predictions violating physical bounds\\
    (d) Clipping/projection effects on accuracy
    \vspace{4cm}}}
    \caption{Boundedness analysis. Neural networks can produce unphysical outputs; this analysis quantifies such violations and their impact.}
    \label{fig:ch9_boundedness}
\end{figure}

\subsection{Reynolds Analogy Consistency}

Figure~\ref{fig:ch9_reynolds_analogy} checks consistency between momentum and thermal predictions.

\begin{figure}[H]
    \centering
    \fbox{\parbox{0.95\textwidth}{\centering\vspace{4cm}
    \textbf{[PLACEHOLDER FIGURE]}\\
    (a) $St$ vs $C_f/2$ scatter plot (Reynolds analogy: $St = C_f/2$ for $Pr = 1$)\\
    (b) Deviation from Reynolds analogy by flow region\\
    (c) Comparison with DNS turbulent Prandtl number data\\
    (d) Thermal-momentum coupling consistency
    \vspace{4cm}}}
    \caption{Reynolds analogy consistency. In equilibrium flows, momentum and thermal transport are linked. The wall function should approximately maintain this relationship.}
    \label{fig:ch9_reynolds_analogy}
\end{figure}

%=============================================================================
\section{Comprehensive Comparison Summary}
\label{sec:ch9_comprehensive_summary}
%=============================================================================

This section provides a unified summary comparing all methods across all evaluation dimensions.

\subsection{Multi-Dimensional Comparison}

Figure~\ref{fig:ch9_radar_chart} presents a radar chart comparing methods across all dimensions.

\begin{figure}[H]
    \centering
    \fbox{\parbox{0.95\textwidth}{\centering\vspace{5cm}
    \textbf{[PLACEHOLDER FIGURE]}\\
    Radar chart with axes:\\
    - Attached flow accuracy\\
    - Separated flow accuracy\\
    - Generalization (geometry)\\
    - Generalization (Reynolds)\\
    - 3D performance\\
    - Computational efficiency\\
    - Mesh robustness\\
    - Numerical stability\\
    - Physical consistency\\
    Comparing: Standard WF, ML-Baseline, ML-PhysicsInputs, ML-PhysicsLayers, ML-PINN
    \vspace{5cm}}}
    \caption{Multi-dimensional comparison radar chart. Each axis represents a normalized score (0--1) for one evaluation dimension. Larger area indicates better overall performance.}
    \label{fig:ch9_radar_chart}
\end{figure}

\subsection{Quantitative Summary Table}

Table~\ref{tab:ch9_master_summary} provides the master comparison table.

\begin{table}[H]
\centering
\caption{Master comparison table across all evaluation dimensions.}
\label{tab:ch9_master_summary}
\small
\begin{tabular}{lccccc}
\toprule
\textbf{Dimension} & \textbf{Std. WF} & \textbf{ML-Base} & \textbf{ML-Phys} & \textbf{ML-Layers} & \textbf{ML-PINN} \\
\midrule
\multicolumn{6}{l}{\textit{Accuracy (MAPE \%)}} \\
\quad $C_f$ attached & --- & --- & --- & --- & --- \\
\quad $C_f$ separated & --- & --- & --- & --- & --- \\
\quad $St$ attached & --- & --- & --- & --- & --- \\
\quad $x_{reatt}$ error (\%) & --- & --- & --- & --- & --- \\
\midrule
\multicolumn{6}{l}{\textit{Efficiency}} \\
\quad Inference ($\mu$s/face) & --- & --- & --- & --- & --- \\
\quad Total overhead (\%) & 0 & --- & --- & --- & --- \\
\midrule
\multicolumn{6}{l}{\textit{Generalization (MAPE \%)}} \\
\quad Mild OOD & --- & --- & --- & --- & --- \\
\quad Strong OOD & --- & --- & --- & --- & --- \\
\quad 3D cases & --- & --- & --- & --- & --- \\
\midrule
\multicolumn{6}{l}{\textit{Robustness}} \\
\quad $y^+$ range & 30--300 & --- & --- & --- & --- \\
\quad Convergence rate (\%) & --- & --- & --- & --- & --- \\
\midrule
\multicolumn{6}{l}{\textit{Physical Consistency}} \\
\quad Sign accuracy (\%) & 50 & --- & --- & --- & --- \\
\quad Bound violations (\%) & 0 & --- & --- & --- & --- \\
\bottomrule
\multicolumn{6}{l}{\small All values to be filled from comprehensive evaluation results.}
\end{tabular}
\end{table}

\subsection{Recommendations by Application}

Based on the comprehensive evaluation, Table~\ref{tab:ch9_recommendations} provides recommendations for different application scenarios.

\begin{table}[H]
\centering
\caption{Wall function recommendations by application scenario.}
\label{tab:ch9_recommendations}
\begin{tabular}{lll}
\toprule
\textbf{Application} & \textbf{Recommended Method} & \textbf{Rationale} \\
\midrule
General purpose (attached flows) & Standard Spalding & Proven, efficient, sufficient \\
Mild separation (diffusers) & ML-PhysicsInputs & Better APG handling \\
Strong separation (BFS, hills) & ML-PINN & Best separation prediction \\
Maximum efficiency & Standard or ML-Baseline & Lowest overhead \\
Maximum accuracy & Wall-resolved (no WF) & Ground truth \\
3D industrial applications & ML-PhysicsInputs & Best generalization \\
Uncertain/novel geometries & ML-PINN & Physics constraints help \\
\bottomrule
\multicolumn{3}{l}{\small Recommendations to be finalized based on evaluation results.}
\end{tabular}
\end{table}

%=============================================================================
\section{Discussion}
\label{sec:ch9_discussion}
%=============================================================================

\subsection{Key Findings}

The comprehensive evaluation reveals several key findings:

\begin{enumerate}
    \item \textbf{[Finding 1]}: To be written based on results---e.g., ``ML wall functions consistently outperform standard approaches in separated flow regions, with X\% reduction in $C_f$ error.''

    \item \textbf{[Finding 2]}: To be written---e.g., ``The computational overhead of ML inference is negligible ($<$X\%) for practical mesh sizes.''

    \item \textbf{[Finding 3]}: To be written---e.g., ``Physics-informed features improve generalization, with the ML-PhysicsInputs model showing the most consistent performance across all test categories.''

    \item \textbf{[Finding 4]}: To be written---e.g., ``3D generalization remains challenging, with performance degradation of X\% compared to 2D cases.''

    \item \textbf{[Finding 5]}: To be written---e.g., ``The ML-PINN model achieves the best physical consistency, with X\% fewer bound violations than ML-Baseline.''
\end{enumerate}

\subsection{Limitations}

Despite the improvements, several limitations remain:

\begin{enumerate}
    \item \textbf{Training data coverage}: The model has not seen all possible flow configurations. Performance degrades for geometries far from training distribution.

    \item \textbf{Thermal predictions in separated flows}: Without benchmark thermal data for separated flows, $q_w$ predictions in recirculation zones remain uncertain.

    \item \textbf{3D effects}: Models trained on 2D data show degraded performance on strongly 3D flows with secondary motions.

    \item \textbf{Extreme conditions}: Performance at very high Reynolds numbers ($Re > 10^6$) or with strong compressibility effects is not validated.
\end{enumerate}

\subsection{Future Work}

Based on the evaluation findings, the following directions are identified for future work:

\begin{enumerate}
    \item \textbf{3D training data}: Generate 3D training cases to improve 3D generalization.

    \item \textbf{Thermal benchmarks}: Incorporate thermal benchmark data (e.g., heated backward step) to improve $q_w$ predictions.

    \item \textbf{Active learning}: Identify high-error regions and generate targeted training data.

    \item \textbf{Uncertainty quantification}: Add prediction uncertainty estimates to flag unreliable predictions.

    \item \textbf{Higher Reynolds numbers}: Extend training to cover industrial Reynolds number ranges.
\end{enumerate}

%=============================================================================
\section{Chapter Summary}
\label{sec:ch9_summary}
%=============================================================================

This chapter presented the integration of ML wall functions into OpenFOAM and comprehensive evaluation across multiple dimensions:

\begin{enumerate}
    \item \textbf{OpenFOAM integration}: A complete C++ boundary condition implementation enables seamless deployment of trained models in production CFD simulations.

    \item \textbf{Accuracy evaluation}: ML wall functions demonstrate improved prediction of wall quantities, especially in separated flow regions where standard wall functions fail to predict negative $\tau_w$.

    \item \textbf{Computational efficiency}: The native C++ backend achieves sub-microsecond inference with negligible total simulation overhead.

    \item \textbf{Generalization}: Performance degrades predictably with distribution shift, but physics-informed models maintain advantages over standard approaches.

    \item \textbf{3D evaluation}: Models trained on 2D data show reasonable 3D generalization, though strong 3D effects cause performance degradation.

    \item \textbf{Robustness}: The ML wall functions maintain numerical stability and operate across a range of mesh densities.

    \item \textbf{Physical consistency}: Physics-informed approaches improve sign prediction and reduce unphysical outputs.
\end{enumerate}

The comprehensive evaluation demonstrates that ML wall functions offer practical improvements over standard approaches, particularly for separated flows, while maintaining computational efficiency suitable for production use. The physics-informed models (ML-PhysicsInputs and ML-PINN) offer the best balance of accuracy, generalization, and physical consistency.

\end{document}
