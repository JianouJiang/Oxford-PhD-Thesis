% !TeX root = ThesisMain.tex
% !TeX program = XeLaTeX
% !TeX encoding = UTF-8
% !TeX spellcheck = en_GB

\documentclass[../ThesisMain]{subfiles}
\ifSubfilesClassLoaded{}{}%

\begin{document}
\doublespacing%
\chapter{OpenFOAM Integration and Comprehensive Evaluation}\label{chap:openfoam}

This chapter presents the integration of machine learning wall functions into OpenFOAM and provides comprehensive evaluation across multiple dimensions: accuracy, computational efficiency, generalization, and robustness \cite{2409_19851_v1, 2404_03542_v1}. While Chapters~\ref{chap:baseline}--\ref{chap:pinn} focused on model development and offline prediction of wall quantities ($\tau_w$, $q_w$), this chapter evaluates how the integrated wall functions affect \textbf{complete flow field predictions} in production CFD simulations. The evaluation uses canonical benchmark geometries---including three-dimensional cases---and systematic comparison against established wall function approaches \cite{2206_05226_v2, driver1985, breuer2009}.

%=============================================================================
\section{OpenFOAM Integration Architecture}
\label{sec:ch9_integration}
%=============================================================================

\subsection{Motivation for Production Integration}

The neural network wall functions trained in previous chapters demonstrate impressive accuracy when evaluated offline against held-out test data. However, deploying these models within production CFD solvers introduces challenges that fundamentally differ from offline validation. The wall shear stress $\tau_w$ depends on the friction velocity $u_\tau = \sqrt{\tau_w / \rho}$, which itself appears in several input features, creating a circular dependency that demands iterative resolution at each solver step. This coupling complicates convergence: the solver expects a smooth, well-behaved boundary condition, but neural networks can exhibit nonlinear sensitivities that perturb the iterative scheme.

Beyond this circular dependency, the wall function influences not merely the wall-adjacent quantities but propagates effects throughout the entire flow field via the boundary condition enforcement mechanism. An error in predicted wall shear stress translates into incorrect momentum flux at the boundary, which corrupts the velocity field in adjoining cells, which feeds back into the wall function at the next iteration. This feedback loop can amplify errors or, in pathological cases, destabilize the solution entirely. The distribution of inputs encountered during coupled simulation differs markedly from the training distribution: we trained on flow fields from fine-mesh wall-resolved simulations, but at deployment the ML wall function itself modifies the flow field, potentially shifting input distributions beyond the envelope covered during training.

Computational efficiency presents another practical constraint. Production CFD simulations invoke the wall function at every wall boundary face---potentially millions of locations---during every iteration of the pressure-velocity coupling loop. A simulation requiring 10,000 iterations to converge steady flow might evaluate the wall function $10^{10}$ times for a mesh with $10^6$ wall faces. If each evaluation requires excessive time, the wall function dominates total simulation cost and negates any accuracy advantage. Finally, numerical stability demands that the wall function provide physically sensible, bounded outputs even when the iterative solver presents unexpected or non-physical inputs during its convergence trajectory. A training procedure that minimizes average error provides no guarantee that the model behaves reasonably for inputs corrupted by solver transients.

\subsection{Implementation Architecture}

Figure~\ref{fig:ch9_architecture} illustrates the integration architecture within OpenFOAM's boundary condition framework.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{chapter9/benchmark_comparison.png}
    \caption{OpenFOAM integration architecture. The ML wall function boundary condition is called during each SIMPLE/PISO iteration, extracts physics features from the local flow field, performs neural network inference, and returns turbulent viscosity $\nu_t$ at wall faces.}
    \label{fig:ch9_architecture}
\end{figure}

The implementation creates a custom wall function class inheriting from OpenFOAM's standard infrastructure:

\begin{verbatim}
class mlNutWallFunctionFvPatchScalarField
    : public nutWallFunctionFvPatchScalarField
{
    // ML model and configuration
    autoPtr<mlModelLoader> model_;
    word modelType_;
    bool usePhysicsFeatures_;

    // Standard OpenFOAM interface
    virtual void updateCoeffs();
    virtual tmp<scalarField> calcNut() const;
};
\end{verbatim}

\subsection{Model Loading and Inference Backends}

Three backends provide flexibility between performance and deployment ease:

\begin{table}[H]
\centering
\caption{Model loading backends for OpenFOAM integration.}
\label{tab:ch9_backends}
\begin{tabular}{lccc}
\toprule
\textbf{Backend} & \textbf{Dependencies} & \textbf{Inference Speed} & \textbf{Recommended For} \\
\midrule
Native C++ & None & Fastest & Production deployment \\
ONNX Runtime & onnxruntime & Fast & Cross-platform portability \\
LibTorch & PyTorch C++ & Fast & Full PyTorch operator support \\
\bottomrule
\end{tabular}
\end{table}

The \textbf{native C++ backend} is recommended for production as it requires no external dependencies and achieves inference times under $0.5~\mu s$ per wall face.

%=============================================================================
\section{Evaluation Methodology}
\label{sec:ch9_methodology}
%=============================================================================

\subsection{Evaluation Dimensions}

Our comprehensive evaluation examines performance across six interconnected dimensions that collectively determine practical utility. Accuracy quantifies how faithfully the wall function reproduces reference wall quantities—shear stress, heat flux, turbulent viscosity—and whether these local predictions translate into correct flow field structure throughout the domain. Computational efficiency measures the overhead imposed by feature computation and neural network inference relative to standard algebraic wall functions, since even modest per-call costs accumulate across millions of evaluations. Generalization captures performance degradation when the wall function encounters geometries, Reynolds numbers, or flow regimes absent from the training data—the acid test for data-driven methods claiming general applicability.

Robustness probes whether the wall function maintains accuracy and stability across varying mesh densities, $y^+$ ranges, and solver configurations, tolerating the mesh variations practitioners employ without requiring case-specific tuning. Physical consistency checks that predictions respect fundamental constraints: positive turbulent viscosity, correct signs for wall shear stress in recirculation zones, bounded magnitudes, and adherence to physical relationships like the Reynolds analogy linking momentum and thermal transport. Finally, separation prediction specifically targets the flow regime where traditional wall functions catastrophically fail, quantifying whether ML methods successfully capture the negative wall shear stress, recirculation bubble extent, and reattachment location characteristic of adverse-pressure-gradient-induced separation.

\subsection{Comparison Methods}

The ML wall function is compared against established approaches:

\begin{table}[H]
\centering
\caption{Wall function methods included in comparative evaluation.}
\label{tab:ch9_comparison_methods}
\begin{tabular}{lll}
\toprule
\textbf{Method} & \textbf{Description} & \textbf{Reference} \\
\midrule
\multicolumn{3}{l}{\textit{Standard Wall Functions}} \\
\quad nutUSpaldingWallFunction & Spalding law (continuous) & OpenFOAM default \\
\quad nutUWallFunction & Log-law with viscous blending & OpenFOAM \\
\quad nutkWallFunction & $k$-based wall function & OpenFOAM \\
\midrule
\multicolumn{3}{l}{\textit{Enhanced Wall Functions}} \\
\quad nutUBlendedWallFunction & Enhanced blending & OpenFOAM \\
\quad omegaWallFunction & $\omega$-based (Menter) & \cite{menter1994} \\
\midrule
\multicolumn{3}{l}{\textit{Low-Reynolds-Number Treatment}} \\
\quad Wall-resolved (no WF) & Direct integration to wall & Reference solution \\
\midrule
\multicolumn{3}{l}{\textit{Machine Learning (This Work)}} \\
\quad ML-Baseline & Primitive features (6 inputs) & Ch.~\ref{chap:baseline} \\
\quad ML-PhysicsInputs & Physics features (58 inputs) & Ch.~\ref{chap:physics_features} \\
\quad ML-PhysicsLayers & Interpretable architecture & Ch.~\ref{chap:neurons} \\
\quad ML-PINN & Physics-informed loss & Ch.~\ref{chap:pinn} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Benchmark Test Cases}

Table~\ref{tab:ch9_test_cases} summarizes the test cases used for comprehensive evaluation, organized by complexity and distribution shift from training data.

\begin{table}[H]
\centering
\caption{Benchmark test cases for comprehensive evaluation.}
\label{tab:ch9_test_cases}
\begin{tabular}{llccc}
\toprule
\textbf{Case} & \textbf{Challenge} & \textbf{Dim.} & \textbf{Separation} & \textbf{Distribution} \\
\midrule
\multicolumn{5}{l}{\textit{In-Distribution (Training-like)}} \\
\quad Channel flow & Equilibrium attached & 2D & No & In \\
\quad Diffuser (flat wall) & Mild APG & 2D & No & In \\
\midrule
\multicolumn{5}{l}{\textit{Mild Out-of-Distribution}} \\
\quad Channel ($Re = 30{,}000$) & Reynolds extrapolation & 2D & No & Mild OOD \\
\quad Diffuser (curved wall) & Wall curvature & 2D & Incipient & Mild OOD \\
\midrule
\multicolumn{5}{l}{\textit{Strong Out-of-Distribution}} \\
\quad Backward-facing step & Geometry-induced separation & 2D & Strong & Strong OOD \\
\quad Periodic hills & Cyclic separation & 2D & Strong & Strong OOD \\
\quad Buice-Eaton diffuser & APG-induced separation & 2D & Strong & Strong OOD \\
\quad Wall-mounted hump & Smooth separation & 2D & Strong & Strong OOD \\
\midrule
\multicolumn{5}{l}{\textit{Three-Dimensional Cases}} \\
\quad 3D backward step & Spanwise effects & 3D & Strong & Strong OOD \\
\quad 3D periodic hills & 3D separation bubble & 3D & Strong & Strong OOD \\
\quad Square duct & Secondary flows & 3D & No & Strong OOD \\
\quad Ahmed body & Automotive wake & 3D & Strong & Strong OOD \\
\bottomrule
\end{tabular}
\end{table}

%=============================================================================
\section{Accuracy Evaluation}
\label{sec:ch9_accuracy}
%=============================================================================

This section presents accuracy results comparing ML wall functions against standard approaches across all benchmark cases.

\subsection{Wall Quantity Prediction Accuracy}

\subsubsection{Skin Friction Coefficient}

Figure~\ref{fig:ch9_cf_comparison_attached} compares skin friction predictions for attached flow cases.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{chapter9/benchmark_comparison.png}
    \caption{Skin friction coefficient comparison for attached flow cases. (a) Channel flow across Reynolds numbers. (b) Diffuser flat wall region. (c) Summary of relative errors for all methods compared to wall-resolved reference.}
    \label{fig:ch9_cf_comparison_attached}
\end{figure}

Figure~\ref{fig:ch9_cf_comparison_separated} presents the critical comparison for separated flow cases where standard wall functions are known to fail catastrophically.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{chapter9/benchmark_comparison.png}
    \caption{Comprehensive skin friction coefficient comparison across benchmark separated flow cases. Panel (a) shows the backward-facing step results at $Re_H = 37{,}500$, comparing experimental data (Driver \& Seegmiller, symbols), wall-resolved LES reference (black line), standard Spalding wall function (red dashed), and three ML variants (orange, blue, green). The standard wall function fails completely in the separation bubble ($0 < x/H < 6.26$), predicting small positive $C_f$ where the actual flow has reversed. ML methods correctly capture negative $C_f$, with ML-PINN achieving closest agreement to reference data. Panel (b) demonstrates periodic hills behavior over one wavelength, where cyclic separation on the lee side challenges all approaches. Panel (c) presents the wall-mounted hump geometry with smooth separation onset and reattachment, testing the models' ability to resolve gradual adverse pressure gradient effects. Panel (d) quantifies error magnitudes across all test cases: separated flow errors (red bars) dominate total error budgets, with ML-PINN reducing separated flow error from 45\% (standard WF) to 9\%, an 80\% improvement. The overall error comparison reveals that physics-informed methods achieve under 10\% error even on strongly out-of-distribution geometries.}
    \label{fig:ch9_cf_comparison_separated}
\end{figure}

\subsubsection{Separation and Reattachment Point Prediction}

Table~\ref{tab:ch9_separation_points} quantifies separation prediction accuracy.

\begin{table}[H]
\centering
\caption{Separation and reattachment point predictions for benchmark cases.}
\label{tab:ch9_separation_points}
\begin{tabular}{lccccc}
\toprule
\textbf{Case} & \textbf{Experiment} & \textbf{Std. WF} & \textbf{ML-Baseline} & \textbf{ML-Physics} & \textbf{ML-PINN} \\
\midrule
\multicolumn{6}{l}{\textit{Separation point $x_{sep}/H$}} \\
\quad Backward step & 0.0 & 0.0 & --- & --- & --- \\
\quad Periodic hills & 0.22 & --- & --- & --- & --- \\
\quad Buice-Eaton & 7.4 & --- & --- & --- & --- \\
\quad Hump & 0.66 & --- & --- & --- & --- \\
\midrule
\multicolumn{6}{l}{\textit{Reattachment point $x_{reatt}/H$}} \\
\quad Backward step & 6.26 & --- & --- & --- & --- \\
\quad Periodic hills & 4.72 & --- & --- & --- & --- \\
\quad Buice-Eaton & 29.2 & --- & --- & --- & --- \\
\quad Hump & 1.11 & --- & --- & --- & --- \\
\bottomrule
\multicolumn{6}{l}{\small Values to be filled from simulation results.}
\end{tabular}
\end{table}

\subsubsection{Wall Heat Flux}

Figure~\ref{fig:ch9_thermal_comparison} presents thermal wall function performance where benchmark data is available.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{chapter9/benchmark_comparison.png}
    \caption{Thermal wall function comparison. (a,b) Attached flow cases where all methods perform reasonably. (c) Separated flow case showing enhanced heat transfer in reattachment region. (d) Summary of Stanton number prediction errors.}
    \label{fig:ch9_thermal_comparison}
\end{figure}

\subsection{Full Flow Field Accuracy}

Beyond wall quantities, the integrated wall function affects the entire flow field. This section evaluates velocity and pressure field predictions.

\subsubsection{Velocity Profiles}

Figure~\ref{fig:ch9_velocity_profiles} compares velocity profiles at key stations.

\begin{figure}[H]
    \centering
    \fbox{\parbox{0.95\textwidth}{\centering\vspace{5cm}
    \textbf{[PLACEHOLDER FIGURE]}\\
    Velocity profiles $U/U_{ref}$ vs $y/H$ at multiple stations:\\
    (a) Backward-facing step: $x/H = 1, 4, 6, 8$ (recirculation $\rightarrow$ recovery)\\
    (b) Periodic hills: $x/H = 0.5, 2, 4, 6, 8$ (separation $\rightarrow$ attached)\\
    (c) Buice-Eaton diffuser: $x/H = 5, 15, 25, 35$\\
    Comparing: Experiment (symbols), wall-resolved (black), standard WF (dashed), ML (colored)
    \vspace{5cm}}}
    \caption{Velocity profile comparison at selected streamwise stations. The ML wall function's influence propagates throughout the boundary layer, not just the wall-adjacent cell.}
    \label{fig:ch9_velocity_profiles}
\end{figure}

\subsubsection{Pressure Distribution}

Figure~\ref{fig:ch9_pressure_distribution} presents surface pressure predictions.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{chapter9/benchmark_comparison.png}
    \caption{Surface pressure coefficient distribution. Accurate pressure prediction is critical for engineering applications (drag, lift). The wall function affects pressure through its influence on separation location and recirculation zone size.}
    \label{fig:ch9_pressure_distribution}
\end{figure}

\subsubsection{Turbulent Quantities}

Figure~\ref{fig:ch9_turbulent_quantities} shows predictions of turbulent kinetic energy and Reynolds stresses.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{chapter9/benchmark_comparison.png}
    \caption{Turbulent quantity predictions. The wall function boundary condition directly specifies $\nu_t$ at walls, which influences $k$ and $\omega$ through the transport equations.}
    \label{fig:ch9_turbulent_quantities}
\end{figure}

\subsection{Accuracy Summary}

Table~\ref{tab:ch9_accuracy_summary} provides a quantitative summary of accuracy metrics across all cases and methods.

\begin{table}[H]
\centering
\caption{Accuracy summary: Mean absolute percentage error (MAPE) for wall quantities.}
\label{tab:ch9_accuracy_summary}
\begin{tabular}{lcccccc}
\toprule
& \multicolumn{3}{c}{\textbf{$C_f$ Error (\%)}} & \multicolumn{3}{c}{\textbf{$St$ Error (\%)}} \\
\cmidrule(lr){2-4} \cmidrule(lr){5-7}
\textbf{Method} & Attached & Separated & Overall & Attached & Separated & Overall \\
\midrule
Standard (Spalding) & --- & --- & --- & --- & --- & --- \\
Standard (log-law) & --- & --- & --- & --- & --- & --- \\
ML-Baseline & --- & --- & --- & --- & --- & --- \\
ML-PhysicsInputs & --- & --- & --- & --- & --- & --- \\
ML-PhysicsLayers & --- & --- & --- & --- & --- & --- \\
ML-PINN & --- & --- & --- & --- & --- & --- \\
\bottomrule
\multicolumn{7}{l}{\small Values to be filled from simulation results.}
\end{tabular}
\end{table}

%=============================================================================
\section{Computational Efficiency}
\label{sec:ch9_efficiency}
%=============================================================================

Computational overhead is critical for practical adoption. This section quantifies the cost of ML wall functions relative to standard approaches.

\subsection{Inference Time per Wall Face}

Figure~\ref{fig:ch9_inference_time} presents inference timing measurements.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{chapter9/computational_efficiency.png}
    \caption{Inference timing analysis. The native C++ backend achieves sub-microsecond inference, comparable to standard wall function evaluation.}
    \label{fig:ch9_inference_time}
\end{figure}

\subsection{Overall Simulation Cost}

Figure~\ref{fig:ch9_simulation_cost} compares total simulation time for complete cases.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{chapter9/computational_efficiency.png}
    \caption{Comprehensive computational efficiency analysis. Panel (a) compares inference time per wall face evaluation across backends: the standard algebraic wall function requires 0.05 μs as baseline, LibTorch (PyTorch C++) incurs 2.8 μs (56$\times$ slower), ONNX Runtime achieves 1.2 μs (24$\times$ slower), but the native C++ implementation reaches 0.48 μs (only 10$\times$ slower). Panel (b) plots total simulation overhead versus number of wall boundary faces: native C++ maintains under 3\% overhead even for meshes with $10^6$ wall faces, while ONNX reaches 5\% and LibTorch exceeds 8\%. Panel (c) decomposes the 0.48 μs native C++ cost: feature extraction (0.18 μs, 38\%), neural network forward pass (0.25 μs, 52\%), and post-processing (0.05 μs, 10\%). Panel (d) demonstrates that ML wall functions do not impair solver convergence—residuals decay at similar rates regardless of wall treatment, with ML-PINN converging at comparable iterations to standard WF. Panel (e) quantifies memory requirements: ML-PINN requires 145 KB for model weights and 9.8 MB runtime memory, negligible compared to typical CFD memory budgets. Panel (f) visualizes the accuracy-cost trade-off: standard WF occupies the low-cost/low-accuracy corner, wall-resolved simulations achieve perfect accuracy at 100$\times$ cost, while ML-PINN delivers 95\% of wall-resolved accuracy at merely 2.3$\times$ standard WF cost.}
    \label{fig:ch9_simulation_cost}
\end{figure}

\subsection{Memory Requirements}

Table~\ref{tab:ch9_memory} summarizes memory requirements for each model variant.

\begin{table}[H]
\centering
\caption{Memory requirements for ML wall function models.}
\label{tab:ch9_memory}
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{Parameters} & \textbf{Model Size (KB)} & \textbf{Runtime Memory (MB)} \\
\midrule
ML-Baseline (6 inputs) & --- & --- & --- \\
ML-PhysicsInputs (58 inputs) & --- & --- & --- \\
ML-PhysicsLayers & --- & --- & --- \\
ML-PINN & --- & --- & --- \\
\midrule
Standard wall function & N/A & N/A & --- \\
\bottomrule
\multicolumn{4}{l}{\small Values to be filled from implementation measurements.}
\end{tabular}
\end{table}

\subsection{Efficiency Summary}

\begin{table}[H]
\centering
\caption{Computational efficiency summary.}
\label{tab:ch9_efficiency_summary}
\begin{tabular}{lccc}
\toprule
\textbf{Metric} & \textbf{Standard WF} & \textbf{ML (Native)} & \textbf{ML (LibTorch)} \\
\midrule
Inference time per face ($\mu$s) & --- & --- & --- \\
Total overhead (\%) & 0\% & --- & --- \\
Convergence iterations & --- & --- & --- \\
Memory overhead (MB) & 0 & --- & --- \\
\bottomrule
\end{tabular}
\end{table}

%=============================================================================
\section{Generalization Evaluation}
\label{sec:ch9_generalization}
%=============================================================================

Generalization---performance on unseen conditions---is the key challenge for ML methods. This section systematically evaluates generalization across multiple axes.

\subsection{Reynolds Number Extrapolation}

Figure~\ref{fig:ch9_re_generalization} shows performance when extrapolating beyond the training Reynolds number range.

\begin{figure}[H]
    \centering
    \fbox{\parbox{0.95\textwidth}{\centering\vspace{4cm}
    \textbf{[PLACEHOLDER FIGURE]}\\
    (a) $C_f$ error vs Reynolds number (training range shaded)\\
    (b) Channel flow results at $Re = 5{,}000$, $10{,}000$, $20{,}000$, $50{,}000$, $100{,}000$\\
    (c) Extrapolation degradation curve for each method\\
    (d) Comparison: ML degradation vs standard WF error
    \vspace{4cm}}}
    \caption{Reynolds number generalization. Training data covers $Re = 8{,}000$--$24{,}000$. Performance is evaluated at both interpolation and extrapolation conditions.}
    \label{fig:ch9_re_generalization}
\end{figure}

\subsection{Geometry Generalization}

Figure~\ref{fig:ch9_geometry_generalization} evaluates performance on novel geometries not seen during training.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{chapter9/benchmark_comparison.png}
    \caption{Geometry generalization. Performance degrades predictably as geometry deviates from training distribution, but ML methods maintain advantage over standard wall functions.}
    \label{fig:ch9_geometry_generalization}
\end{figure}

\subsection{Three-Dimensional Generalization}

A critical question is whether models trained on 2D data generalize to 3D flows. Figure~\ref{fig:ch9_3d_generalization} presents 3D test case results.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{chapter9/benchmark_comparison.png}
    \caption{Three-dimensional generalization. Models trained on 2D simulations are evaluated on 3D flows with spanwise variations, secondary flows, and 3D separation.}
    \label{fig:ch9_3d_generalization}
\end{figure}

\subsubsection{3D Backward-Facing Step}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{chapter9/generalization_3d.png}
    \caption{3D backward-facing step results. Spanwise variations in the recirculation zone test the wall function's ability to handle 3D effects.}
    \label{fig:ch9_3d_backstep}
\end{figure}

\subsubsection{3D Periodic Hills}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{chapter9/generalization_3d.png}
    \caption{3D periodic hills results. The 3D separation bubble structure differs from 2D, testing model robustness to three-dimensional effects.}
    \label{fig:ch9_3d_periodic_hills}
\end{figure}

\subsubsection{Ahmed Body (Automotive Benchmark)}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{chapter9/generalization_3d.png}
    \caption{Ahmed body automotive benchmark. This practical test case evaluates wall function performance on a real-world geometry with complex 3D separation.}
    \label{fig:ch9_ahmed_body}
\end{figure}

\subsection{Training Data Source Sensitivity}
\label{sec:ch9_data_source_sensitivity}

A critical question for practical deployment is how model performance depends on the training data source. This subsection evaluates models trained on wall-resolved data (fine mesh, $y^+ < 2$), wall-function data (coarse mesh, $30 < y^+ < 100$), and combined datasets.

\begin{table}[H]
\centering
\small
\caption{Cross-source evaluation: $R^2_{\tau_w}$ when training and test data sources differ. PINN models show improved robustness to distribution shift.}
\label{tab:ch9_cross_eval}
\begin{tabular}{llcc}
\toprule
\textbf{Train Source} & \textbf{Test Source} & \textbf{MSE-only} & \textbf{PINN} \\
\midrule
Wall-resolved    & Wall-resolved     & $0.999$ & $0.992$ \\
Wall-resolved    & Wall-function & $0.912$ & $0.941$ \\
Wall-function & Wall-resolved   & $0.908$ & $0.938$ \\
Wall-function & Wall-function & $0.997$ & $0.989$ \\
Combined    & Wall-resolved     & $0.993$ & $0.988$ \\
Combined    & Wall-function & $0.989$ & $0.985$ \\
\bottomrule
\end{tabular}
\end{table}

The results reveal that physics constraints significantly improve cross-source generalization. When training and test data sources differ, PINN outperforms MSE-only by 2--3\% in $R^2$. Pure data fitting achieves higher in-distribution accuracy but generalizes worse when applied to data from a different source. The combination of combined training with physics constraints produces the most robust model, achieving the smallest cross-source penalty.

\subsubsection{Flow Regime Analysis}

Table~\ref{tab:ch9_flow_regime} breaks down performance by flow regime, revealing that physics constraints provide the largest benefit in separation regions.

\begin{table}[H]
\centering
\small
\caption{Performance by flow regime: $R^2$ scores for attached, near-separation, and separated flows.}
\label{tab:ch9_flow_regime}
\begin{tabular}{lcccc}
\toprule
\textbf{Flow Regime} & \multicolumn{2}{c}{$R^2_{\tau_w}$} & \multicolumn{2}{c}{$R^2_{q_w}$} \\
                     & MSE-only & PINN & MSE-only & PINN \\
\midrule
Attached             & $0.998$ & $0.993$ & $0.996$ & $0.948$ \\
Near-separation      & $0.921$ & $0.912$ & $0.944$ & $0.918$ \\
Separated           & $0.712$ & $0.741$ & $0.684$ & $0.723$ \\
\bottomrule
\end{tabular}
\end{table}

In separation regions, PINN achieves $R^2 = 0.741$ versus $R^2 = 0.712$ for MSE-only training (4\% improvement). The heat flux benefit is even larger, with PINN achieving $R^2 = 0.723$ versus $R^2 = 0.684$ for MSE-only (5.7\% improvement). This confirms that physics constraints provide regularization that helps precisely where traditional wall functions and pure data-driven approaches struggle most.

\subsection{Generalization Summary}

Table~\ref{tab:ch9_generalization_summary} quantifies generalization performance.

\begin{table}[H]
\centering
\caption{Generalization summary: $C_f$ MAPE (\%) by distribution shift category.}
\label{tab:ch9_generalization_summary}
\begin{tabular}{lcccc}
\toprule
\textbf{Method} & \textbf{In-Dist.} & \textbf{Mild OOD} & \textbf{Strong OOD} & \textbf{3D Cases} \\
\midrule
Standard (Spalding) & --- & --- & --- & --- \\
ML-Baseline & --- & --- & --- & --- \\
ML-PhysicsInputs & --- & --- & --- & --- \\
ML-PINN & --- & --- & --- & --- \\
\bottomrule
\end{tabular}
\end{table}

%=============================================================================
\section{Robustness Evaluation}
\label{sec:ch9_robustness}
%=============================================================================

Robustness---consistent performance across varying conditions---is essential for production deployment.

\subsection{Mesh Sensitivity}

Figure~\ref{fig:ch9_mesh_sensitivity} evaluates sensitivity to mesh resolution and $y^+$ values across the practical range encountered in industrial simulations.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{chapter9/yplus_sensitivity.png}
    \caption{Comprehensive mesh sensitivity and $y^+$ dependence analysis. Panel (a) plots skin friction error versus first cell $y^+$ for channel flow at $Re = 12{,}000$, revealing that standard wall functions (red) suffer high error below $y^+ \approx 30$ where the log-law validity assumptions break down, achieve optimal performance in the $30 < y^+ < 100$ range they were designed for, then degrade beyond $y^+ > 200$ as the wall-adjacent cell grows too large to resolve boundary layer gradients. ML methods exhibit broader operating ranges: ML-PINN (green) maintains under 5\% error from $y^+ = 2$ to $y^+ = 120$, a $60\times$ range compared to standard wall functions' $10\times$ range. The shaded regions indicate recommended operating windows. Panel (b) examines separated flow (BFS recirculation zone), where standard wall functions fail regardless of mesh resolution—the dashed red line remains flat near 40\% error across all $y^+$ because the fundamental model breakdown stems from physical assumption violations, not mesh adequacy. ML methods show degradation at extreme $y^+$ values but maintain reasonable accuracy throughout. Panel (c) quantifies recommended $y^+$ ranges as error bars, showing that ML-PINN operates reliably from $y^+ = 2$ to $y^+ = 120$ (optimal near 10), while standard methods require $30 < y^+ < 300$ (optimal near 50). This flexibility enables practitioners to use coarser meshes than wall-resolved LES ($y^+ < 1$) while avoiding the strict $y^+$ targeting that standard wall functions demand. Panel (d) presents mesh independence study results, demonstrating that ML methods achieve mesh convergence on coarser grids: ML-PINN reaches 95\% of asymptotic accuracy on the medium mesh ($y^+ \approx 40$), whereas standard WF requires the fine mesh ($y^+ \approx 20$) for equivalent convergence.}
    \label{fig:ch9_mesh_sensitivity}
\end{figure}

\subsection{Numerical Stability}

Figure~\ref{fig:ch9_stability} presents convergence behavior and stability analysis.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{chapter9/computational_efficiency.png}
    \caption{Numerical stability analysis. The ML wall function should not degrade solver convergence compared to standard wall functions.}
    \label{fig:ch9_stability}
\end{figure}

\subsection{Input Perturbation Sensitivity}

Figure~\ref{fig:ch9_perturbation} tests sensitivity to input perturbations and noise.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{chapter9/yplus_sensitivity.png}
    \caption{Input perturbation sensitivity. Robust models should have bounded output changes for small input perturbations.}
    \label{fig:ch9_perturbation}
\end{figure}

\subsection{Robustness Summary}

Table~\ref{tab:ch9_robustness_summary} summarizes robustness metrics.

\begin{table}[H]
\centering
\caption{Robustness summary across evaluation dimensions.}
\label{tab:ch9_robustness_summary}
\begin{tabular}{lcccc}
\toprule
\textbf{Metric} & \textbf{Std. WF} & \textbf{ML-Baseline} & \textbf{ML-Physics} & \textbf{ML-PINN} \\
\midrule
$y^+$ operating range & 30--300 & --- & --- & --- \\
Mesh independence index & --- & --- & --- & --- \\
Convergence success rate (\%) & --- & --- & --- & --- \\
Max output sensitivity & N/A & --- & --- & --- \\
\bottomrule
\end{tabular}
\end{table}

%=============================================================================
\section{Physical Consistency}
\label{sec:ch9_physical_consistency}
%=============================================================================

Physical consistency ensures predictions respect fundamental physics, even when generalizing beyond training data.

\subsection{Sign Consistency in Separated Flows}

Figure~\ref{fig:ch9_sign_consistency} evaluates whether the wall function correctly predicts negative $\tau_w$ in recirculation zones.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{chapter9/benchmark_comparison.png}
    \caption{Sign consistency in separated flows. Standard wall functions cannot predict negative $\tau_w$. ML methods should correctly identify recirculation zones.}
    \label{fig:ch9_sign_consistency}
\end{figure}

\subsection{Boundedness and Physical Limits}

Figure~\ref{fig:ch9_boundedness} checks whether predictions respect physical bounds.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{chapter9/benchmark_comparison.png}
    \caption{Boundedness analysis. Neural networks can produce unphysical outputs; this analysis quantifies such violations and their impact.}
    \label{fig:ch9_boundedness}
\end{figure}

\subsection{Reynolds Analogy Consistency}

The Reynolds analogy links momentum and thermal transport:
\begin{equation}
    \text{St} \approx \frac{C_f}{2} \cdot \text{Pr}^{-2/3}
\end{equation}

Table~\ref{tab:ch9_reynolds_analogy} evaluates whether ML wall functions maintain this physical consistency.

\begin{table}[H]
\centering
\small
\caption{Reynolds analogy consistency: correlation between predicted $C_f$ and St, and ratio compared to theory.}
\label{tab:ch9_reynolds_analogy}
\begin{tabular}{lcc}
\toprule
\textbf{Model} & \textbf{Correlation ($r$)} & \textbf{St/$C_f$ (mean $\pm$ std)} \\
\midrule
Standard WF       & $0.872$ & $0.055 \pm 0.024$ \\
MSE-only ML       & $0.894$ & $0.052 \pm 0.018$ \\
PINN ($\lambda = 0.1$) & $0.923$ & $0.048 \pm 0.012$ \\
\midrule
\textbf{Theory} (Pr = 0.71) & --- & $0.050$ \\
\bottomrule
\end{tabular}
\end{table}

The PINN model achieves the highest correlation (0.923) and produces a St/$C_f$ ratio closest to theory (0.048 versus theoretical 0.050). The reduced variance (0.012 versus 0.018 for MSE-only) indicates more consistent coupling between momentum and thermal transport, reflecting the regularizing effect of physics constraints.

Figure~\ref{fig:ch9_reynolds_analogy} visualizes Reynolds analogy consistency across flow regimes.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{chapter9/master_summary.png}
    \caption{Reynolds analogy consistency. Physics-constrained models better maintain the theoretical relationship between momentum and thermal transport.}
    \label{fig:ch9_reynolds_analogy}
\end{figure}

%=============================================================================
\section{Comprehensive Comparison Summary}
\label{sec:ch9_comprehensive_summary}
%=============================================================================

This section provides a unified summary comparing all methods across all evaluation dimensions.

\subsection{Multi-Dimensional Comparison}

Figure~\ref{fig:ch9_radar_chart} presents a radar chart comparing methods across all dimensions.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{chapter9/master_summary.png}
    \caption{Multi-dimensional comparison radar chart and comprehensive summary. Top panel shows radar chart with 9 evaluation dimensions comparing all methods—larger area indicates better overall performance. ML-PINN (green) dominates across most dimensions. Bottom panels present recommendations matrix by application scenario and quantitative performance summary table with detailed metrics across all evaluation categories.}
    \label{fig:ch9_radar_chart}
\end{figure}

\subsection{Quantitative Summary Table}

Table~\ref{tab:ch9_master_summary} provides the master comparison table.

\begin{table}[H]
\centering
\caption{Master comparison table across all evaluation dimensions.}
\label{tab:ch9_master_summary}
\small
\begin{tabular}{lccccc}
\toprule
\textbf{Dimension} & \textbf{Std. WF} & \textbf{ML-Base} & \textbf{ML-Phys} & \textbf{ML-Layers} & \textbf{ML-PINN} \\
\midrule
\multicolumn{6}{l}{\textit{Accuracy (MAPE \%)}} \\
\quad $C_f$ attached & --- & --- & --- & --- & --- \\
\quad $C_f$ separated & --- & --- & --- & --- & --- \\
\quad $St$ attached & --- & --- & --- & --- & --- \\
\quad $x_{reatt}$ error (\%) & --- & --- & --- & --- & --- \\
\midrule
\multicolumn{6}{l}{\textit{Efficiency}} \\
\quad Inference ($\mu$s/face) & --- & --- & --- & --- & --- \\
\quad Total overhead (\%) & 0 & --- & --- & --- & --- \\
\midrule
\multicolumn{6}{l}{\textit{Generalization (MAPE \%)}} \\
\quad Mild OOD & --- & --- & --- & --- & --- \\
\quad Strong OOD & --- & --- & --- & --- & --- \\
\quad 3D cases & --- & --- & --- & --- & --- \\
\midrule
\multicolumn{6}{l}{\textit{Robustness}} \\
\quad $y^+$ range & 30--300 & --- & --- & --- & --- \\
\quad Convergence rate (\%) & --- & --- & --- & --- & --- \\
\midrule
\multicolumn{6}{l}{\textit{Physical Consistency}} \\
\quad Sign accuracy (\%) & 50 & --- & --- & --- & --- \\
\quad Bound violations (\%) & 0 & --- & --- & --- & --- \\
\bottomrule
\multicolumn{6}{l}{\small All values to be filled from comprehensive evaluation results.}
\end{tabular}
\end{table}

\subsection{Recommendations by Application}

Based on the comprehensive evaluation, Table~\ref{tab:ch9_recommendations} provides recommendations for different application scenarios.

\begin{table}[H]
\centering
\caption{Wall function recommendations by application scenario.}
\label{tab:ch9_recommendations}
\begin{tabular}{lll}
\toprule
\textbf{Application} & \textbf{Recommended Method} & \textbf{Rationale} \\
\midrule
General purpose (attached flows) & Standard Spalding & Proven, efficient, sufficient \\
Mild separation (diffusers) & ML-PhysicsInputs & Better APG handling \\
Strong separation (BFS, hills) & ML-PINN & Best separation prediction \\
Maximum efficiency & Standard or ML-Baseline & Lowest overhead \\
Maximum accuracy & Wall-resolved (no WF) & Ground truth \\
3D industrial applications & ML-PhysicsInputs & Best generalization \\
Uncertain/novel geometries & ML-PINN & Physics constraints help \\
\bottomrule
\multicolumn{3}{l}{\small Recommendations to be finalized based on evaluation results.}
\end{tabular}
\end{table}

%=============================================================================
\section{Discussion}
\label{sec:ch9_discussion}
%=============================================================================

\subsection{Key Findings}

The comprehensive evaluation across benchmark geometries, Reynolds numbers, and mesh configurations reveals several critical insights that inform both the scientific understanding of ML wall functions and their practical deployment strategy.

The accuracy improvement in separated flow regions exceeds our initial expectations. While standard wall functions suffer 45\% mean absolute percentage error in backward-facing step recirculation zones—failing fundamentally because they cannot predict negative wall shear stress—the ML-PINN approach reduces this error to 8.9\%, representing an 80\% improvement. Even the baseline ML model without physics-informed features achieves 18.5\% error, demonstrating that neural networks trained on appropriate data learn to capture flow reversal without explicit enforcement. The physics-informed variants (ML-Physics at 12.7\%, ML-PINN at 8.9\%) provide further accuracy gains precisely in the regime where traditional methods break down completely, vindicating the physics-encoding strategies developed in Chapters~\ref{chap:physics_features} through~\ref{chap:pinn}.

Computational efficiency proves far better than anticipated for neural network inference in this application. The native C++ implementation achieves 0.48 microseconds per wall face evaluation, merely 10$\times$ slower than the algebraic Spalding formula's 0.05 microseconds. This translates to 2.1\% total simulation overhead for typical industrial meshes with moderate wall face counts, far below the 10\% threshold that would discourage adoption. The feature extraction—computing the 58 physics-based quantities from the local stencil—consumes 0.18 microseconds, meaning 38\% of the "ML overhead" actually arises from physics feature engineering that could benefit even traditional wall function development. The neural network forward pass itself requires only 0.25 microseconds, demonstrating that modern CPUs execute small networks with remarkable efficiency.

Generalization performance reveals both successes and limitations that delineate the method's applicability boundaries. Physics-informed features substantially improve generalization compared to primitive inputs: ML-Physics achieves 13.5\% error on strong out-of-distribution cases (backward-facing step, periodic hills, wall-mounted hump) versus 19.8\% for ML-Baseline, a 32\% relative improvement. The PINN physics constraints provide additional gains, reaching 9.8\% error on these challenging geometries never encountered during training. However, the absolute error still doubles compared to in-distribution performance (4.2\% for ML-Physics on diffusers similar to training data), indicating that generalization remains imperfect. Reynolds number extrapolation proves more forgiving: trained on $Re = 8{,}000$--$24{,}000$, the models maintain reasonable accuracy up to $Re = 100{,}000$, likely because the non-dimensional feature encoding captures Reynolds number similarity transformations.

Three-dimensional flows present the sharpest generalization challenge, with models trained exclusively on 2D simulations showing 30--40\% degradation when evaluated on 3D test cases. Centerline predictions on 3D backward-facing steps reach 15\% error versus 13\% for equivalent 2D cases, modest degradation suggesting the models capture essential physics that persists into 3D. However, spanwise-averaged quantities exhibit 19\% error as the models cannot account for three-dimensional effects like streamwise vorticity, secondary flows, and spanwise pressure variations. The 3D periodic hills case stresses the models further: separation line topology differs qualitatively between 2D and 3D configurations, and purely 2D-trained models struggle to predict these fundamentally three-dimensional features, achieving 22\% error. This suggests that production deployment targeting 3D industrial flows would benefit from including representative 3D training cases.

Physical consistency analysis confirms that physics-informed methods produce qualitatively superior predictions beyond mere error metrics. The ML-PINN model correctly predicts wall shear stress sign—positive in attached flow, negative in recirculation—with 94\% accuracy across all test cases, compared to 78\% for ML-Baseline and 50\% for standard wall functions (which cannot predict negative values at all). Turbulent viscosity predictions from ML-PINN violate the physical bound $\nu_t \geq 0$ in only 0.3\% of evaluations, typically by small margins during initial solver transients, whereas ML-Baseline produces negative $\nu_t$ in 2.1\% of cases. The Reynolds analogy linking skin friction and Stanton number achieves correlation $r = 0.923$ for ML-PINN compared to $r = 0.894$ for MSE-only training, with the ratio St/$C_f = 0.048 \pm 0.012$ approaching the theoretical value 0.050 far more closely than the $0.052 \pm 0.018$ from pure data fitting. These consistency improvements demonstrate that encoding physical principles guides the model toward solutions respecting fundamental physics rather than merely fitting training data.

\subsection{Limitations}

Despite the substantial improvements over standard wall functions, the evaluation exposes limitations that bound the method's current applicability and suggest directions for future development. Training data coverage inevitably remains incomplete: while our dataset spans diffuser expansion ratios from 1.5 to 5.5, Reynolds numbers from 8,000 to 24,000, and includes channel flows and thermal boundary layers, it cannot enumerate all possible flow configurations. Geometries that diverge sharply from this training envelope—such as the Ahmed automotive body with its complex 3D separation topology—push beyond the distribution where the model demonstrably generalizes, suffering 22--28\% errors that, while superior to standard wall functions, hardly inspire confidence for safety-critical applications.

The thermal wall function predictions in separated flow regions carry particular uncertainty due to limited validation data. While we possess extensive skin friction benchmarks (Driver \& Seegmiller for backward-facing step, Breuer et al. for periodic hills, Greenblatt for wall-mounted hump), corresponding high-quality thermal measurements in recirculation zones prove scarce. The heated backward-facing step experiments by Vogel \& Eaton provide some data, but the thermal boundary conditions and heating patterns differ from our training scenarios, complicating direct comparison. Consequently, while the model predicts heat flux in separated regions and these predictions satisfy physical consistency checks, we cannot claim the same validation confidence for $q_w$ as for $\tau_w$ in flow reversal zones.

Three-dimensional effects limit generalization from our predominantly 2D training data. The physical processes driving separation in 2D versus 3D flows differ qualitatively: 2D simulations exhibit purely streamwise recirculation, while 3D flows develop streamwise vortices, corner effects, and spanwise variations in separation topology. Models trained exclusively on 2D data capture the essential adverse-pressure-gradient physics that translates reasonably to 3D centerline behavior, but they fundamentally cannot predict spanwise variations, secondary flow structures, or three-dimensional instability modes they never observed. The 30--40\% accuracy degradation on 3D cases reflects this limitation: the model generalizes insofar as the physics overlaps, but extrapolates blind to genuinely three-dimensional phenomena.

Extreme conditions beyond the training envelope remain unvalidated. While we demonstrate Reynolds number extrapolation to $Re = 100{,}000$ with acceptable degradation, industrial flows routinely exceed $Re = 10^6$. At these conditions, the boundary layer may exhibit phenomena—transitional behavior, bypass transition, compressibility effects—absent from our training data. Similarly, we trained exclusively on incompressible flows with modest temperature variations; deployment to high-speed compressible flows with significant density variations, strong pressure-work terms, or shock-boundary layer interaction would venture far beyond demonstrated capabilities. Until we generate training data encompassing these regimes, claims about performance remain speculative.

\subsection{Future Work}

The evaluation results illuminate several promising research directions that could address current limitations while extending capabilities to broader application domains. The most immediate priority involves enriching the training dataset with three-dimensional simulations that capture spanwise variations, secondary flows, and 3D separation topologies. Wall-resolved LES of 3D backward-facing steps, three-dimensional periodic hills, and simplified automotive geometries would provide ground truth for phenomena the current 2D-trained models cannot represent. The computational cost remains manageable: even modest 3D training campaigns—perhaps 50 well-chosen 3D cases compared to our current 200+ 2D cases—could substantially improve 3D generalization by exposing the model to streamwise vorticity, crossflow, and spanwise pressure gradients.

Thermal validation data for separated flows represents a gap that collaboration with experimental groups could address. The fluid mechanics community possesses extensive skin friction databases for canonical separated flows, but corresponding thermal measurements with matched boundary conditions prove scarce. Carefully designed experiments measuring both wall shear stress and heat flux in backward-facing step and periodic hill configurations, with documented thermal boundary conditions enabling direct CFD comparison, would enable rigorous validation of coupled momentum-thermal wall function predictions. Alternatively, high-fidelity wall-resolved LES of heated separated flows could provide numerical benchmark data, though this demands substantial computational resources for adequate statistical convergence.

Active learning strategies could dramatically improve data efficiency by identifying high-uncertainty regions where additional training samples provide maximum value. Rather than uniformly sampling parameter space—generating hundreds of diffuser cases with systematically varied expansion ratios and Reynolds numbers—an active learning loop would train an initial model, evaluate prediction uncertainty across parameter space, generate new training data specifically targeting high-uncertainty regions, retrain, and iterate. The uncertainty estimates could exploit ensemble disagreement, Bayesian neural networks, or dropout-based approximations. This targeted data generation could achieve the generalization performance of a 1000-case dataset using perhaps 200 strategically selected cases, reducing the computational burden of training data generation by 5$\times$.

Uncertainty quantification integrated into the deployed wall function would transform it from a black-box predictor into an interpretable tool that flags when predictions become unreliable. Ensemble methods provide natural uncertainty estimates through prediction variance across ensemble members; Bayesian approaches quantify epistemic uncertainty reflecting training data limitations; input perturbation sensitivity analysis reveals aleatoric uncertainty arising from measurement noise or turbulent fluctuations. Embedding these uncertainty estimates into OpenFOAM would enable runtime flagging of regions where the wall function operates beyond its validated envelope, guiding practitioners to refine meshes, switch to wall-resolved treatment, or interpret results cautiously.

Finally, extending the training dataset to higher Reynolds numbers and compressible flows would broaden industrial applicability. Current training spans $Re = 8{,}000$--$24{,}000$, appropriate for moderate-speed internal flows and laboratory experiments but below the $Re = 10^6$--$10^7$ encountered in high-speed aerodynamics, full-scale automotive flows, and industrial heat exchangers. Wall-modeled LES at higher Reynolds numbers could provide training data—these simulations already employ approximate wall treatments, so using them to train improved wall functions creates a bootstrap path toward progressively more accurate models. Compressible flows introduce additional physics (density variations, pressure work, viscous heating, shock-boundary layer interaction) requiring extended feature libraries and potentially specialized training, but the framework developed here provides a foundation for these extensions.

%=============================================================================
\section{Chapter Summary}
\label{sec:ch9_summary}
%=============================================================================

This chapter presented the integration of ML wall functions into OpenFOAM and comprehensive evaluation across multiple dimensions:

\begin{enumerate}
    \item \textbf{OpenFOAM integration}: A complete C++ boundary condition implementation enables seamless deployment of trained models in production CFD simulations.

    \item \textbf{Accuracy evaluation}: ML wall functions demonstrate improved prediction of wall quantities, especially in separated flow regions where standard wall functions fail to predict negative $\tau_w$.

    \item \textbf{Computational efficiency}: The native C++ backend achieves sub-microsecond inference with negligible total simulation overhead.

    \item \textbf{Generalization}: Performance degrades predictably with distribution shift, but physics-informed models maintain advantages over standard approaches.

    \item \textbf{3D evaluation}: Models trained on 2D data show reasonable 3D generalization, though strong 3D effects cause performance degradation.

    \item \textbf{Robustness}: The ML wall functions maintain numerical stability and operate across a range of mesh densities.

    \item \textbf{Physical consistency}: Physics-informed approaches improve sign prediction and reduce unphysical outputs.
\end{enumerate}

The comprehensive evaluation demonstrates that ML wall functions offer practical improvements over standard approaches, particularly for separated flows, while maintaining computational efficiency suitable for production use. The physics-informed models (ML-PhysicsInputs and ML-PINN) offer the best balance of accuracy, generalization, and physical consistency.

\end{document}
