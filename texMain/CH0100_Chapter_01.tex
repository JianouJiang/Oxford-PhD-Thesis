% !TeX root = ThesisMain.tex
% !TeX program = XeLaTeX
% !TeX encoding = UTF-8
% !TeX spellcheck = en_GB

\documentclass[../ThesisMain]{subfiles}
\ifSubfilesClassLoaded{}{}%

\begin{document}
\doublespacing%
\chapter{Introduction}\label{chap:introduction}%

The accurate prediction of turbulent flows near solid boundaries remains one of the outstanding challenges in computational fluid dynamics \cite{2010_12226_v1, 2312_14902_v1, moser1999}. While the Reynolds-averaged Navier-Stokes equations provide a framework for simulating turbulent flows at practical Reynolds numbers \cite{reynolds1895, 1701_07102_v2}, their solution requires resolving the steep gradients that develop in the near-wall region---or alternatively, bridging this region with models that capture the essential physics without explicit resolution \cite{launder1974, spalding1961}. These bridging models, known as wall functions, have served engineering practice for over half a century \cite{wolfshtein1969, karman1930}. Yet as computational demands grow more complex---involving flow separation, thermal coupling, and unsteady phenomena---the limitations of classical wall functions become increasingly apparent \cite{2509_05886_v1, 2411_17095_v1, driver1985}. This thesis develops a machine learning framework to address these limitations \cite{ling2016, 1701_07102_v2, raissi2019physics}, creating wall function models that combine the computational efficiency of classical approaches with the flexibility to learn directly from high-fidelity simulation data \cite{2312_14902_v1, 2206_05226_v2, milano2002}.

\section{Industrial Motivation: Where Wall Functions Matter}
\label{sec:intro_industrial}

The economic and engineering significance of accurate wall function modeling extends across virtually every industry that relies on fluid flow prediction \cite{2212_08989_v3, 2209_02051_v1}. The wall shear stress $\tau_w$ directly determines drag forces that govern fuel consumption in transportation \cite{schlatter2010, 2002_01222_v1}, while the wall heat flux $q_w$ controls thermal management in everything from electronic cooling to nuclear reactor safety \cite{2201_03200_v2, 2202_00435_v1}. Errors in wall function predictions propagate into the quantities that engineers ultimately care about: drag coefficients, heat transfer rates, pressure drops, and system efficiencies \cite{2309_02109_v1, 2404_03542_v1}. The breadth of affected industries underscores the fundamental importance of this seemingly specialized topic.

In aerospace and gas turbine applications, modern aircraft wings operate at Reynolds numbers exceeding $10^7$, where even small errors in skin friction prediction translate to significant fuel burn penalties---a 1\% error in drag coefficient for a commercial aircraft represents millions of dollars in annual fuel costs across a fleet. The situation is even more critical in gas turbine engines, where blade cooling effectiveness depends on accurate prediction of heat transfer coefficients; underpredicting heat flux leads to blade failure, while overpredicting leads to inefficient use of cooling air that reduces engine efficiency. The automotive industry faces similar challenges, with vehicle manufacturers investing heavily in CFD-based aerodynamic optimization to reduce drag and improve fuel efficiency. For electric vehicles, where range anxiety drives consumer decisions, accurate drag prediction becomes especially important. The complex geometry of vehicle underbodies, wheel wells, and cooling systems creates flow separation and reattachment patterns that challenge classical wall functions, and wind tunnel validation remains essential precisely because CFD predictions using standard wall treatments are often unreliable in these regions.

The built environment presents its own demanding applications. Indoor air quality and thermal comfort depend on accurate prediction of airflow patterns near walls, floors, and ceilings, with buoyancy-driven flows developing near heated or cooled surfaces proving particularly challenging for classical wall functions that assume negligible density variations. Given that buildings account for approximately 40\% of global energy consumption, improvements in HVAC system design through better CFD modeling could yield substantial energy savings. Nuclear reactor thermal-hydraulics represents perhaps the most consequential application: safety analysis requires accurate prediction of heat transfer from fuel elements to coolant, and the severe consequences of underpredicting heat flux---potential fuel damage or meltdown---compel regulatory bodies to require substantial safety margins. More accurate wall function models could reduce these margins while maintaining safety, enabling more efficient reactor designs. Similarly, marine and offshore engineering depends on turbulent boundary layer predictions at high Reynolds numbers for ship hull resistance, offshore platform loading, and underwater vehicle performance, with fuel costs typically representing 50--70\% of a commercial vessel's operating expenses.

These diverse applications share a common challenge: the flows of engineering interest almost never satisfy the equilibrium assumptions of classical wall functions. Pressure gradients, flow separation, thermal coupling, and geometric complexity are the norm rather than the exception. The industrial motivation for improved wall function modeling is thus not academic curiosity but practical necessity.

\section{The Near-Wall Challenge in Turbulent Flow Simulation}
\label{sec:intro_challenge}

Turbulent boundary layers present a fundamental challenge for computational fluid dynamics: the steep velocity gradients that develop near solid surfaces require either extremely fine meshes to resolve directly or simplified models to bridge the near-wall region \cite{prandtl1904, 2006_12483_v1, 1905_03634_v1}. The physics underlying this challenge---the layered structure of turbulent boundary layers, the transition from viscous-dominated to turbulent-dominated regions, and the universal scaling laws that emerge---is developed in detail in Chapter~\ref{chap:literature}. Here we focus on the practical implications for computational cost and the resulting need for wall function models.

Resolving near-wall gradients directly requires mesh cells with wall-normal dimensions on the order of the viscous length scale, which for high Reynolds number flows translates to meshes with millions or billions of cells concentrated in thin layers near walls \cite{blasius1908, 2301_00106_v2}. The computational cost scales approximately as $Re^{1.8}$ for wall-resolved Large Eddy Simulation, making direct resolution impractical for most industrial applications. When thermal effects are present, the thermal boundary layer introduces additional thin regions requiring resolution, further increasing computational demands.

\subsection{The Computational Cost of Wall Resolution}

Table~\ref{tab:mesh_comparison} illustrates the stark contrast between wall-resolved and wall-modeled simulations for a representative internal flow.

\begin{table}[H]
    \centering
    \caption{Approximate mesh requirements for wall-resolved versus wall-modeled RANS simulation of channel flow. Wall-resolved meshes require $y^+_1 < 1$; wall-modeled meshes use $y^+_1 \approx 30$--100.}
    \label{tab:mesh_comparison}
    \small
    \begin{tabular}{cccc}
        \toprule
        \textbf{Reynolds Number} & \textbf{Wall-Resolved} & \textbf{Wall-Modeled} & \textbf{Reduction} \\
        \midrule
        $Re = 10^4$ & $\sim 10^5$ & $\sim 10^4$ & 10$\times$ \\
        $Re = 10^5$ & $\sim 10^6$ & $\sim 10^5$ & 10$\times$ \\
        $Re = 10^6$ & $\sim 10^7$ & $\sim 10^5$ & 100$\times$ \\
        $Re = 10^7$ & $\sim 10^8$ & $\sim 10^6$ & 100$\times$ \\
        \bottomrule
    \end{tabular}
\end{table}

For industrial applications at $Re \sim 10^7$, wall-resolved simulations require meshes that push the limits of current supercomputing capabilities. Even with wall functions, a full aircraft simulation may require tens of millions of cells and days of compute time. The mesh reduction enabled by wall functions is not merely convenient---it is often the difference between computationally feasible and infeasible.

However, this computational savings comes at the cost of accuracy. Wall functions approximate the physics of the near-wall region rather than resolving it, and these approximations fail when the underlying assumptions are violated. The challenge addressed by this thesis is to create wall function models that maintain the computational efficiency of classical approaches while substantially improving accuracy under non-equilibrium conditions.

\subsection{Classical Wall Function Theory}

Wall functions offer an alternative to direct resolution: rather than resolving the near-wall region explicitly, the first computational cell is placed in the logarithmic layer (typically at $y^+ \approx 30$--100), and algebraic relationships derived from similarity theory provide the wall shear stress and heat flux \cite{launder1974}. This approach reduces mesh requirements by factors of 10--100, bringing turbulent flow simulation within reach of routine engineering analysis. The classical wall functions developed by Launder and Spalding in the 1970s assume local equilibrium between turbulence production and dissipation, small pressure gradients, and attached flow---conditions well-satisfied in fully-developed channel flow and flat plate boundary layers \cite{moser1999, lee2015, schlatter2010}. The mathematical framework underlying these wall functions, including the derivation and limitations of the logarithmic law of the wall, is developed comprehensively in Chapter~\ref{chap:literature}.

\section{Limitations of Classical Wall Functions}
\label{sec:intro_limitations}

The equilibrium assumptions underlying classical wall functions fail precisely where engineering interest is greatest. As flow decelerates under an adverse pressure gradient \cite{clauser1954, stratford1959}, the boundary layer thickens, the velocity profile deviates from logarithmic form \cite{coles1956, 2408_08897_v1}, and the assumption of local equilibrium breaks down; the classical wall function overpredicts wall shear stress and cannot capture the onset of separation \cite{2509_05886_v1, 2511_18552_v1}. The situation becomes more severe in separated regions, where the wall shear stress becomes negative \cite{driver1985, breuer2009, 2312_03295_v2}, making the friction velocity $u_\tau = \sqrt{|\tau_w|/\rho}$ ill-defined for determining wall-normal distance scaling. More fundamentally, the reversed flow near the wall bears no resemblance to the attached boundary layer profile that the logarithmic law describes \cite{2409_04143_v1, 2411_17095_v1}.

Thermal predictions face additional challenges. Wall functions based on Reynolds analogy \cite{kader1981, 2211_00601_v1} assume that the turbulent transport of heat parallels that of momentum, but this assumption fails when buoyancy effects become significant \cite{2502_05577_v2} or when the turbulent Prandtl number varies substantially from its commonly-assumed value of 0.85 \cite{1910_03097_v1}. Complex geometries introduce yet further complications: three-dimensional flows over curved surfaces, in corners, or around obstacles develop secondary flows and pressure gradient effects that violate the two-dimensional, streamwise-invariant assumptions of classical wall function theory. These limitations manifest as systematic errors in practical CFD simulations---flow separation is predicted too late (or not at all), heat transfer is overpredicted in recirculation zones, and the overall solution accuracy degrades precisely in the regions of greatest engineering interest.

\subsection{A Motivating Example: The Asymmetric Diffuser}

The asymmetric diffuser provides a compelling illustration of classical wall function failure. Consider a channel where one wall remains flat while the opposite wall diverges at an angle, creating an adverse pressure gradient that eventually causes flow separation on the expanding wall. This geometry, used extensively in this thesis, spans conditions from mild deceleration to massive separation depending on the expansion ratio and divergence angle.

Figure~\ref{fig:diffuser_schematic} illustrates the flow physics. In the attached region upstream of separation, classical wall functions perform adequately: the flow approximates equilibrium, and the logarithmic law provides reasonable estimates of wall shear stress. As the adverse pressure gradient intensifies, however, the boundary layer responds in ways that the equilibrium assumption cannot capture. The velocity profile distorts from logarithmic form, turbulence production exceeds dissipation, and the classical wall function progressively overpredicts $\tau_w$.

At separation, the classical approach fails catastrophically. The wall shear stress passes through zero and becomes negative in the recirculating region. The friction velocity becomes imaginary, breaking the non-dimensionalization that underlies the entire wall function framework. Most CFD codes handle this by switching to an ad-hoc treatment---often linear interpolation through the zero crossing---but such fixes have no physical basis and typically produce poor predictions of the separation and reattachment locations.

The reattachment region presents additional challenges. As the separated flow reattaches, it brings high-momentum fluid toward the wall, creating a recovery profile that differs substantially from the equilibrium logarithmic law. Classical wall functions, designed for attached flow, cannot capture this recovery process.

This single geometry thus encapsulates the full range of wall function challenges: equilibrium flow, adverse pressure gradient effects, separation, reversed flow, and reattachment. A wall function model that performs well across all these conditions would represent a substantial advance over classical approaches.

\begin{figure}[H]
    \centering
    \begin{tikzpicture}[scale=0.9]
        % Channel walls
        \draw[thick] (0,0) -- (10,0);
        \draw[thick] (0,2) -- (3,2) -- (7,3.5) -- (10,3.5);

        % Flow direction
        \draw[->, thick, blue] (0.5,1) -- (2,1) node[midway, above] {$U_\infty$};

        % Separation bubble
        \draw[dashed, red] (4.5,2.2) .. controls (5.5,2.8) and (6.5,2.8) .. (7.5,2.5);
        \draw[->, red, thin] (5.5,2.5) -- (5,2.3);

        % Labels
        \node at (2,0.5) {\small Attached};
        \node at (5.5,1.5) {\small Separation};
        \node at (8.5,2) {\small Reattachment};

        % y+ annotation
        \draw[<->, thin] (1,-0.3) -- (1,0.3);
        \node at (1,-0.6) {\tiny $y^+_1 \sim 30$};

        % tau_w annotations
        \node at (2,-0.4) {\small $\tau_w > 0$};
        \node at (6,-0.4) {\small $\tau_w < 0$};
        \node at (9,-0.4) {\small $\tau_w > 0$};
    \end{tikzpicture}
    \caption{Schematic of flow through an asymmetric diffuser, illustrating attached flow, separation, recirculation, and reattachment. Classical wall functions fail in the separation and recirculation regions where $\tau_w \leq 0$.}
    \label{fig:diffuser_schematic}
\end{figure}

\section{The Machine Learning Opportunity}
\label{sec:intro_ml_opportunity}

Machine learning offers a fundamentally different approach to wall function modeling. Rather than deriving algebraic relationships from similarity theory and asymptotic analysis, machine learning models learn directly from data. High-fidelity simulations---Direct Numerical Simulation (DNS) or well-resolved Large Eddy Simulation (LES)---provide training data that captures the full complexity of near-wall turbulence, including the departures from equilibrium that classical theory cannot accommodate.

Neural networks, as universal function approximators, can represent the nonlinear relationships between near-wall flow quantities and wall fluxes without the limiting assumptions of classical theory. A network trained on diverse flow conditions can interpolate (and potentially extrapolate) to conditions not explicitly represented in the training data, guided by the underlying patterns in the physics rather than by prescribed functional forms.

However, purely data-driven approaches face their own challenges. Neural networks may learn spurious correlations that happen to work within the training distribution but fail catastrophically outside it. Without physical constraints, predictions may violate conservation laws, produce non-physical negative shear stresses, or extrapolate wildly in regions where training data is sparse. The generalization problem---ensuring that models trained on canonical flows perform well in practical applications---remains the central challenge of machine learning for turbulence modeling.

This thesis addresses these challenges through a unified framework that combines data-driven learning with physics-informed constraints. The key insight is that physics knowledge can be incorporated at multiple levels: in the selection and construction of input features, in the architecture of the neural network itself, and in the loss function used during training. By encoding physical principles at each of these levels, we create models that are both flexible enough to learn from data and constrained enough to respect fundamental physics.

\section{Three Approaches to Physics-Informed Learning}
\label{sec:intro_three_approaches}

This thesis develops and compares three complementary methods for incorporating physics knowledge into neural network wall functions. Each method operates at a different level of the machine learning pipeline, and together they provide a comprehensive framework for physics-informed wall function modeling.

\subsection{Method A: Physics-Encoded Input Features}

The first approach encodes physics in the \textit{input representation}. Rather than providing the neural network with raw simulation outputs (velocity components, pressure, temperature at mesh points), we construct non-dimensional features that respect the scaling laws of turbulent boundary layers.

Classical wall function theory teaches us that the relevant variables are wall-scaled quantities: $y^+ = y u_\tau / \nu$, $u^+ = u / u_\tau$, and similar dimensionless groups. These scalings collapse boundary layer data across Reynolds numbers, suggesting that neural networks should receive inputs in these natural coordinates. We extend this idea to construct a library of 58 physics-based features encompassing wall-scaled distances and velocities ($y^+$, $u^+$, $v^+$), pressure gradient terms ($p^+_x = \nu / (\rho u_\tau^3) \cdot \partial p / \partial x$), velocity gradient and curvature quantities, thermal equivalents ($T^+$, $y^+_T$ based on thermal friction velocity), and deformation tensor invariants. Chapter~\ref{chap:physics_features} demonstrates that this physics-encoded input representation enables generalization across Reynolds numbers and achieves accuracy comparable to much larger sets of primitive variables.

\subsection{Method B: Physics-Guided Network Architecture}

The second approach investigates what neural networks learn \textit{internally} when trained on primitive inputs. Even without explicit physics encoding in the inputs, neural networks must construct internal representations to solve the wall function prediction problem, raising the question of whether these representations correspond to physically meaningful quantities. Through systematic correlation analysis between hidden layer neuron activations and physics-based features, we find that networks spontaneously discover physics-relevant quantities: neurons in trained networks correlate strongly with $y^+$, $\ln(y^+)$, and pressure gradient scalings---precisely the quantities that classical wall function theory identifies as important. Most remarkably, certain features emerge across network architectures of different sizes; a network with 8 hidden neurons and one with 32 hidden neurons both develop neurons correlated with wall-scaled distance. This \textit{architecture invariance} suggests that these features are fundamental to the learning problem rather than artifacts of particular network configurations. Chapter~\ref{chap:neurons} explores these findings, validating the physics-based input design of Method A while revealing the implicit physics learning capabilities of neural networks.

\subsection{Method C: Physics-Constrained Loss Functions}

The third approach encodes physics in the \textit{training objective}. Standard supervised learning minimizes prediction error on training data, but nothing prevents the network from learning solutions that violate physical conservation laws. Physics-Informed Neural Networks (PINNs) address this limitation by adding physics residuals to the loss function: $\mathcal{L} = \mathcal{L}_{\text{data}} + \lambda_{\text{physics}} \mathcal{L}_{\text{physics}}$. For wall functions, we develop a local stencil-based PINN that evaluates conservation law residuals on the same near-wall stencil used for input features, penalizing violations of streamwise and wall-normal momentum conservation, energy conservation, and mass conservation (incompressibility). Unlike global PINNs that require automatic differentiation over entire computational domains, this local approach maintains computational efficiency while enforcing physics constraints where they matter most: in the near-wall region. Chapter~\ref{chap:pinn} develops this approach and characterizes the trade-off between fitting accuracy and physical consistency.

\subsection{Complementary Methods}

These three methods are not mutually exclusive but rather address physics encoding at different stages of the machine learning pipeline: Method A operates during data preparation through non-dimensional features, Method B influences model design through implicit feature discovery, and Method C shapes the training objective through conservation constraints. A comprehensive wall function model might combine all three---physics-encoded inputs, architectures designed to facilitate physics discovery, and loss functions that enforce conservation. The experimental chapters of this thesis evaluate each method independently to understand their individual contributions before considering combinations.

\section{Research Questions}
\label{sec:intro_questions}

This thesis addresses five interconnected research questions that progressively build understanding of physics-informed machine learning for wall functions.

The first and most fundamental question (\textbf{RQ1}) asks whether machine learning models can predict wall shear stress and heat flux accurately across diverse flow conditions. This baseline question establishes whether neural networks can learn the wall function mapping at all, and if so, what accuracy is achievable with different input representations and architectures. Building on this foundation, \textbf{RQ2} investigates whether physics-based input features improve generalization compared to primitive variables. If networks can learn equally well from primitives and from physics features, the additional effort of computing physics-based inputs may not be justified; conversely, if physics features enable better generalization, they provide a concrete prescription for feature engineering in wall function applications.

The third question (\textbf{RQ3}) probes what neural networks learn internally when trained on primitive inputs---do they spontaneously discover physics-based features? This question connects Methods A and B: if networks discover physics features internally, it validates the importance of these features while suggesting that explicit encoding may not be strictly necessary. \textbf{RQ4} then examines whether physics-constrained training improves extrapolation to conditions outside the training distribution. Method C sacrifices some in-distribution accuracy for physical consistency, and the critical question is whether this trade-off pays off when models encounter flows not represented in training data.

Finally, \textbf{RQ5} addresses the practical question of whether ML wall functions can be deployed in production CFD codes and outperform classical approaches. Academic demonstrations on test sets must ultimately translate to practical utility, and this question determines the engineering viability of the proposed methods.

\section{Research Objectives}
\label{sec:intro_objectives}

This thesis pursues four interconnected objectives that structure the experimental chapters. The first objective is to develop a systematic methodology for generating training data, since high-quality training data is the foundation of any machine learning approach. We develop a dual-mesh methodology that pairs fine-mesh (wall-resolved) simulations with coarse-mesh simulations of the same flow: the fine mesh provides ground-truth wall shear stress and heat flux, while the coarse mesh provides the input features that a deployed model would have access to. This approach generates naturally-paired training data across 244 configurations spanning attached and separated flows.

The second objective concerns the design of physics-informed input features. Classical wall functions succeed because they use the right non-dimensional variables---$y^+$, $u^+$, and similar quantities that collapse boundary layer profiles across Reynolds numbers---and we extend this insight by developing a library of 58 physics-based features derived from the near-wall stencil data. These features encode quantities like local velocity gradients, pressure gradients, curvature terms, and thermal variables in wall-scaled and non-dimensional forms, providing the neural network with inputs that respect the scaling laws of turbulent boundary layers.

The third objective explores physics-guided architectures and training methods. Beyond input features, physical knowledge can be encoded in the network architecture and training procedure; we investigate whether neural networks spontaneously discover physics-based features in their hidden layers, and we develop physics-constrained loss functions that penalize violations of conservation laws during training.

The fourth and final objective is to integrate trained models into production CFD solvers. Academic machine learning research often stops at demonstrating accuracy on test sets, but we complete the engineering loop by implementing trained models as boundary conditions in OpenFOAM, validating performance on benchmark cases beyond the training distribution, and comparing against classical wall functions in both two-dimensional and three-dimensional configurations.

\section{Thesis Contributions}
\label{sec:intro_contributions}

This thesis makes the following contributions to the field of machine learning for computational fluid dynamics:

\begin{enumerate}
    \item \textbf{A dual-mesh training data generation methodology} that systematically produces paired input-output data for wall function learning across diverse flow conditions. The resulting dataset of 25,485 training samples spans Reynolds numbers 8,000--24,000 and geometric configurations from mild acceleration to strong separation.

    \item \textbf{A physics-based feature library} comprising 58 non-dimensional quantities derived from the near-wall stencil. Systematic experiments demonstrate that a core subset of 11 physics features achieves accuracy comparable to much larger primitive-variable input sets, while providing interpretability advantages.

    \item \textbf{Evidence for architecture-invariant feature discovery}, showing that neural networks trained on primitive inputs spontaneously develop hidden layer neurons correlated with physics-based quantities like $y^+$, $\ln(y^+)$, and pressure gradient scalings. This finding validates the physics-based input design and suggests that certain features emerge naturally from the learning problem.

    \item \textbf{A local stencil-based Physics-Informed Neural Network} that enforces conservation laws (momentum, energy, mass) as soft constraints during training. Unlike global PINNs that require automatic differentiation over entire domains, this approach evaluates physics residuals on the same local stencil used for predictions, maintaining computational efficiency while improving physical consistency.

    \item \textbf{A complete OpenFOAM integration} including C++ boundary condition implementation, Python-to-C++ model export infrastructure, and validation on benchmark cases including backward-facing steps and periodic hills.
\end{enumerate}

\section{Scope and Limitations}
\label{sec:intro_scope}

To maintain focus and depth, this thesis adopts specific boundaries on the problems addressed. In terms of flow regimes, we consider incompressible, low-Mach-number flows with Reynolds numbers in the range 8,000--24,000; while the methodology extends in principle to compressible flows and higher Reynolds numbers, validation is limited to the incompressible regime. All simulations use Reynolds-Averaged Navier-Stokes (RANS) equations with the $k$-$\omega$ SST turbulence model, and although the wall functions developed here could be adapted for Large Eddy Simulation, LES-specific considerations such as subgrid scale modeling near walls are not addressed.

Training data comes from two-dimensional channel, diffuser, and nozzle configurations, with validation on two-dimensional benchmark cases (backward-facing step, periodic hills) and preliminary three-dimensional results; comprehensive three-dimensional validation remains future work. For thermal coupling, we consider passive scalar transport with fixed wall temperatures, leaving conjugate heat transfer, radiative effects, and strongly-coupled thermal-fluid interactions outside the scope. All simulations assume steady-state conditions, with extension to unsteady flows---where temporal history effects may be important---identified as a direction for future research. These limitations define the domain within which the thesis results are validated, and extensions beyond these boundaries are discussed in Chapter~\ref{chap:conclusion} as opportunities for future work.

\section{Thesis Outline}
\label{sec:intro_outline}

This thesis is organized into nine chapters that progressively develop the physics-informed machine learning framework for wall functions. Following this introduction, Chapter~\ref{chap:literature} traces the evolution of wall function modeling from Prandtl's boundary layer theory through modern machine learning approaches, situating the present work within this intellectual history and identifying the specific gaps that the thesis addresses. Chapter~\ref{chap:methodology} describes the computational setup, including the dual-mesh approach for generating paired training data, the OpenFOAM simulation configurations, and the post-processing pipeline that constructs stencil-based inputs from raw simulation outputs.

The core technical contributions appear in Chapters~\ref{chap:baseline}--\ref{chap:pinn}. Chapter~\ref{chap:baseline} presents the baseline machine learning approach---fully-connected neural networks trained on primitive flow variables to predict wall shear stress and heat flux---establishing the achievable accuracy and identifying limitations that motivate the physics-informed extensions. Chapter~\ref{chap:physics_features} develops the library of 58 physics-based input features and systematically compares performance against primitive-variable inputs (Method A), identifying a core set of features that balance accuracy, interpretability, and computational cost. Chapter~\ref{chap:neurons} investigates what neural networks learn internally when trained on primitive inputs (Method B), demonstrating through correlation analysis that networks discover wall-scaled quantities even without explicit physics encoding. Chapter~\ref{chap:pinn} develops and evaluates the local stencil-based PINN approach (Method C), incorporating conservation law residuals into the training loss function and characterizing the trade-off between fitting accuracy and physical consistency.

The final chapters address practical deployment and conclusions. Chapter~\ref{chap:separation} tackles the distinct challenge of detecting separated regions where classical wall functions fail most severely, developing classifiers that distinguish attached from separated flow based on stencil inputs. Chapter~\ref{chap:openfoam} presents the production implementation, including C++ boundary condition code, model export utilities, and comprehensive validation on benchmark geometries beyond the training distribution. Chapter~\ref{chap:conclusion} summarizes the contributions, discusses limitations, and outlines directions for future research including extension to higher Reynolds numbers, three-dimensional flows, and unsteady applications.

\section{Chapter Summary}
\label{sec:intro_summary}

Turbulent flow simulation requires accurate treatment of the near-wall region where steep gradients develop. Classical wall functions, while computationally efficient, fail under conditions of adverse pressure gradients, flow separation, and strong thermal coupling---precisely the conditions of greatest engineering interest. The economic implications span industries from aerospace to building ventilation, motivating sustained research into improved wall function models.

Machine learning offers the potential to learn wall function models directly from high-fidelity data, but purely data-driven approaches risk learning spurious correlations that fail outside the training distribution. This thesis develops a physics-informed machine learning framework that combines the flexibility of neural networks with the constraints of physical law. Three complementary methods encode physics knowledge at different stages: in the input features (Method A), in the network architecture through implicit discovery (Method B), and in the training loss function (Method C).

The resulting models are integrated into OpenFOAM for practical CFD applications, demonstrating improved performance over classical approaches across a range of benchmark configurations. The following chapters develop this framework systematically, from data generation through production deployment, contributing both methodological advances and practical tools to the field of machine learning for computational fluid dynamics.

\end{document}
