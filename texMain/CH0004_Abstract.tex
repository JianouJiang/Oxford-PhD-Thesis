% !TeX root = ThesisMain.tex
% !TeX program = XeLaTeX
% !TeX encoding = UTF-8
% !TeX spellcheck = en_GB

\documentclass[../ThesisMain]{subfiles}
\ifSubfilesClassLoaded{}{}%

\begin{document}
\doublespacing%
\begin{abstract}
Wall functions are essential for practical computational fluid dynamics (CFD), bridging the computational gap between fully-resolved near-wall simulations and affordable mesh densities. However, classical algebraic wall functions fail catastrophically in separated flows and strong adverse pressure gradients---precisely the conditions most critical for engineering applications. This thesis develops a physics-informed machine learning framework for universal wall functions that achieve accurate predictions across attached, separated, and transitional flow regimes while maintaining computational efficiency suitable for industrial deployment.

The methodology centres on a dual-mesh training approach: coarse meshes ($y^+ \approx 5$--10) provide local stencil inputs representing practical CFD conditions, while wall-resolved fine meshes ($y^+ < 2$) supply ground truth for wall shear stress and heat flux. A comprehensive dataset of 244 parametric simulations spanning diffusers, nozzles, and channels generates 25,485 training samples covering Reynolds numbers from 6,000 to 24,000 and expansion ratios from 0.5 to 4.5.

Three complementary physics-informed strategies are developed and systematically evaluated. Physics-encoded inputs transform 90 primitive stencil variables into 58 non-dimensional features grounded in turbulence theory, with a curated subset of 11 core features achieving equivalent accuracy---an 8-fold reduction in input dimensionality. Physics-guided hidden layers reveal that neural networks spontaneously learn representations strongly correlated ($|r| > 0.8$) with established turbulence quantities, with architecture-invariant features emerging across networks of varying sizes. Physics-constrained learning incorporates local conservation residuals for momentum, energy, and mass into the training objective, improving extrapolation to out-of-distribution conditions.

The framework achieves 80\% error reduction compared to standard wall functions in separated flow regions (8.9\% versus 45\% mean absolute percentage error), while maintaining 60\% improvement even in attached flows where traditional methods were designed to operate. A machine learning classifier detects flow separation from local stencil data with 98.8\% accuracy, enabling a hybrid strategy that applies ML wall functions only where needed. Integration into OpenFOAM demonstrates production readiness with only 2.1\% computational overhead, achieved through native C++ neural network inference at 0.48 microseconds per wall face.

The combined framework---physics-encoded features, interpretable hidden representations, conservation constraints, and adaptive separation detection---establishes universal wall functions applicable across the full spectrum of engineering flow conditions, from equilibrium boundary layers to complex separated flows with heat transfer.

\textbf{Keywords:} Universal wall functions, Physics-informed neural networks, Reduced-order modelling, Turbulent boundary layers, Flow separation, Heat transfer, OpenFOAM, Computational fluid dynamics
\end{abstract}
\newpage   
\end{document}